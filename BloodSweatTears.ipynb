{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.54)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (2.32.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\sebert\\appdata\\roaming\\python\\python312\\site-packages (from yfinance) (4.3.6)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (2025.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (3.17.9)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (4.13.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sebert\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31->yfinance) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31->yfinance) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31->yfinance) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31->yfinance) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sebert\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (7.8.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: prawcore<3,>=2.4 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from praw) (2.4.0)\n",
      "Requirement already satisfied: update_checker>=0.18 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from praw) (1.8.0)\n",
      "Requirement already satisfied: click in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sebert\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from prawcore<3,>=2.4->praw) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sebert\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sebert\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install praw nltk pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Sebert\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Sebert\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching AAPL data from 2023-09-01 to 2023-10-31 with 1h interval...\n",
      "Fetching AAPL data from 2023-11-01 to 2023-12-31 with 1h interval...\n",
      "Fetching AAPL data from 2024-01-01 to 2024-03-01 with 1h interval...\n",
      "Fetching AAPL data from 2024-03-02 to 2024-05-01 with 1h interval...\n",
      "Fetching AAPL data from 2024-05-02 to 2024-07-01 with 1h interval...\n",
      "Fetching AAPL data from 2024-07-02 to 2024-08-31 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching AAPL data from 2024-09-01 to 2024-10-31 with 1h interval...\n",
      "Fetching AAPL data from 2024-11-01 to 2024-12-31 with 1h interval...\n",
      "Fetching AAPL data from 2025-01-01 to 2025-02-10 with 1h interval...\n",
      "[DEBUG] Technical indicator columns added: ['Close', 'High_AAPL', 'Low_AAPL', 'Open_AAPL', 'Volume_AAPL', 'SMA20', 'SMA44', 'SMA50', 'SMA100', 'SMA200', 'EMA12', 'EMA26', 'MACD', 'MACD_Signal', 'MACD_Histogram']\n",
      "Fetching GOOG data from 2023-09-01 to 2023-10-31 with 1h interval...\n",
      "Fetching GOOG data from 2023-11-01 to 2023-12-31 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching GOOG data from 2024-01-01 to 2024-03-01 with 1h interval...\n",
      "Fetching GOOG data from 2024-03-02 to 2024-05-01 with 1h interval...\n",
      "Fetching GOOG data from 2024-05-02 to 2024-07-01 with 1h interval...\n",
      "Fetching GOOG data from 2024-07-02 to 2024-08-31 with 1h interval...\n",
      "Fetching GOOG data from 2024-09-01 to 2024-10-31 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching GOOG data from 2024-11-01 to 2024-12-31 with 1h interval...\n",
      "Fetching GOOG data from 2025-01-01 to 2025-02-10 with 1h interval...\n",
      "[DEBUG] Technical indicator columns added: ['Close', 'High_GOOG', 'Low_GOOG', 'Open_GOOG', 'Volume_GOOG', 'SMA20', 'SMA44', 'SMA50', 'SMA100', 'SMA200', 'EMA12', 'EMA26', 'MACD', 'MACD_Signal', 'MACD_Histogram']\n",
      "Fetching MSFT data from 2023-09-01 to 2023-10-31 with 1h interval...\n",
      "Fetching MSFT data from 2023-11-01 to 2023-12-31 with 1h interval...\n",
      "Fetching MSFT data from 2024-01-01 to 2024-03-01 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching MSFT data from 2024-03-02 to 2024-05-01 with 1h interval...\n",
      "Fetching MSFT data from 2024-05-02 to 2024-07-01 with 1h interval...\n",
      "Fetching MSFT data from 2024-07-02 to 2024-08-31 with 1h interval...\n",
      "Fetching MSFT data from 2024-09-01 to 2024-10-31 with 1h interval...\n",
      "Fetching MSFT data from 2024-11-01 to 2024-12-31 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching MSFT data from 2025-01-01 to 2025-02-10 with 1h interval...\n",
      "[DEBUG] Technical indicator columns added: ['Close', 'High_MSFT', 'Low_MSFT', 'Open_MSFT', 'Volume_MSFT', 'SMA20', 'SMA44', 'SMA50', 'SMA100', 'SMA200', 'EMA12', 'EMA26', 'MACD', 'MACD_Signal', 'MACD_Histogram']\n",
      "Fetching AMZN data from 2023-09-01 to 2023-10-31 with 1h interval...\n",
      "Fetching AMZN data from 2023-11-01 to 2023-12-31 with 1h interval...\n",
      "Fetching AMZN data from 2024-01-01 to 2024-03-01 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching AMZN data from 2024-03-02 to 2024-05-01 with 1h interval...\n",
      "Fetching AMZN data from 2024-05-02 to 2024-07-01 with 1h interval...\n",
      "Fetching AMZN data from 2024-07-02 to 2024-08-31 with 1h interval...\n",
      "Fetching AMZN data from 2024-09-01 to 2024-10-31 with 1h interval...\n",
      "Fetching AMZN data from 2024-11-01 to 2024-12-31 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching AMZN data from 2025-01-01 to 2025-02-10 with 1h interval...\n",
      "[DEBUG] Technical indicator columns added: ['Close', 'High_AMZN', 'Low_AMZN', 'Open_AMZN', 'Volume_AMZN', 'SMA20', 'SMA44', 'SMA50', 'SMA100', 'SMA200', 'EMA12', 'EMA26', 'MACD', 'MACD_Signal', 'MACD_Histogram']\n",
      "Fetching NVDA data from 2023-09-01 to 2023-10-31 with 1h interval...\n",
      "Fetching NVDA data from 2023-11-01 to 2023-12-31 with 1h interval...\n",
      "Fetching NVDA data from 2024-01-01 to 2024-03-01 with 1h interval...\n",
      "Fetching NVDA data from 2024-03-02 to 2024-05-01 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching NVDA data from 2024-05-02 to 2024-07-01 with 1h interval...\n",
      "Fetching NVDA data from 2024-07-02 to 2024-08-31 with 1h interval...\n",
      "Fetching NVDA data from 2024-09-01 to 2024-10-31 with 1h interval...\n",
      "Fetching NVDA data from 2024-11-01 to 2024-12-31 with 1h interval...\n",
      "Fetching NVDA data from 2025-01-01 to 2025-02-10 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Technical indicator columns added: ['Close', 'High_NVDA', 'Low_NVDA', 'Open_NVDA', 'Volume_NVDA', 'SMA20', 'SMA44', 'SMA50', 'SMA100', 'SMA200', 'EMA12', 'EMA26', 'MACD', 'MACD_Signal', 'MACD_Histogram']\n",
      "[DEBUG] AAPL stock data shape: (2462, 17), columns: ['Close', 'High_AAPL', 'Low_AAPL', 'Open_AAPL', 'Volume_AAPL', 'SMA20', 'SMA44', 'SMA50', 'SMA100', 'SMA200', 'EMA12', 'EMA26', 'MACD', 'MACD_Signal', 'MACD_Histogram', 'Datetime', 'Date']\n",
      "Fetching up to 200 Reddit posts for AAPL in r/wallstreetbets...\n",
      "Fetched 200 posts for AAPL.\n",
      "[DEBUG] sentiment_daily shape: (177, 1), columns: ['avg_sentiment']\n",
      "\n",
      "--- Final merged DataFrame for AAPL ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2263 entries, 2023-10-12 16:30:00 to 2025-02-07 20:30:00\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Close           2263 non-null   float64\n",
      " 1   High_AAPL       2263 non-null   float64\n",
      " 2   Low_AAPL        2263 non-null   float64\n",
      " 3   Open_AAPL       2263 non-null   float64\n",
      " 4   Volume_AAPL     2263 non-null   int64  \n",
      " 5   SMA20           2263 non-null   float64\n",
      " 6   SMA44           2263 non-null   float64\n",
      " 7   SMA50           2263 non-null   float64\n",
      " 8   SMA100          2263 non-null   float64\n",
      " 9   SMA200          2263 non-null   float64\n",
      " 10  EMA12           2263 non-null   float64\n",
      " 11  EMA26           2263 non-null   float64\n",
      " 12  MACD            2263 non-null   float64\n",
      " 13  MACD_Signal     2263 non-null   float64\n",
      " 14  MACD_Histogram  2263 non-null   float64\n",
      " 15  avg_sentiment   2263 non-null   float64\n",
      "dtypes: float64(15), int64(1)\n",
      "memory usage: 300.6 KB\n",
      "None\n",
      "                          Close   High_AAPL    Low_AAPL   Open_AAPL  \\\n",
      "Datetime                                                              \n",
      "2023-10-12 16:30:00  180.354904  182.279999  180.330002  182.279999   \n",
      "2023-10-12 17:30:00  179.639999  180.630005  179.039993  180.339996   \n",
      "2023-10-12 18:30:00  180.399994  180.479996  179.490005  179.634995   \n",
      "2023-10-12 19:30:00  180.729996  180.815002  180.389999  180.399994   \n",
      "2023-10-13 13:30:00  180.529999  181.929993  180.360001  181.419998   \n",
      "\n",
      "                     Volume_AAPL       SMA20       SMA44       SMA50  \\\n",
      "Datetime                                                               \n",
      "2023-10-12 16:30:00      5641539  179.399960  177.270032  176.666064   \n",
      "2023-10-12 17:30:00      6607337  179.436961  177.417077  176.818828   \n",
      "2023-10-12 18:30:00      4772922  179.507460  177.592532  176.989828   \n",
      "2023-10-12 19:30:00      5779607  179.584705  177.774123  177.167228   \n",
      "2023-10-13 13:30:00      9761566  179.637205  177.927761  177.328628   \n",
      "\n",
      "                         SMA100      SMA200       EMA12       EMA26      MACD  \\\n",
      "Datetime                                                                        \n",
      "2023-10-12 16:30:00  174.668442  176.837938  180.092702  178.901182  1.191520   \n",
      "2023-10-12 17:30:00  174.698742  176.789738  180.023055  178.955909  1.067146   \n",
      "2023-10-12 18:30:00  174.745742  176.748438  180.081046  179.062878  1.018167   \n",
      "2023-10-12 19:30:00  174.801742  176.706513  180.180884  179.186368  0.994516   \n",
      "2023-10-13 13:30:00  174.850142  176.664163  180.234594  179.285897  0.948697   \n",
      "\n",
      "                     MACD_Signal  MACD_Histogram  avg_sentiment  \n",
      "Datetime                                                         \n",
      "2023-10-12 16:30:00     1.073825        0.117695            0.0  \n",
      "2023-10-12 17:30:00     1.072489       -0.005343            0.0  \n",
      "2023-10-12 18:30:00     1.061625       -0.043457            0.0  \n",
      "2023-10-12 19:30:00     1.048203       -0.053687            0.0  \n",
      "2023-10-13 13:30:00     1.028302       -0.079604            0.0  \n",
      "                          Close   High_AAPL    Low_AAPL   Open_AAPL  \\\n",
      "Datetime                                                              \n",
      "2025-02-07 16:30:00  228.400604  229.419998  228.195007  229.085007   \n",
      "2025-02-07 17:30:00  229.298904  229.440002  228.363297  228.389999   \n",
      "2025-02-07 18:30:00  227.880005  229.500000  227.830002  229.289993   \n",
      "2025-02-07 19:30:00  228.000000  228.580002  227.789993  227.889999   \n",
      "2025-02-07 20:30:00  227.710007  228.149994  227.259995  227.990005   \n",
      "\n",
      "                     Volume_AAPL       SMA20       SMA44       SMA50  \\\n",
      "Datetime                                                               \n",
      "2025-02-07 16:30:00      3763438  231.256165  232.656043  233.289398   \n",
      "2025-02-07 17:30:00      3721234  231.114110  232.454654  233.137996   \n",
      "2025-02-07 18:30:00      2602577  230.892660  232.223972  232.946996   \n",
      "2025-02-07 19:30:00      2965606  230.653160  231.986472  232.778096   \n",
      "2025-02-07 20:30:00      5030649  230.563660  231.724200  232.551296   \n",
      "\n",
      "                         SMA100      SMA200       EMA12       EMA26      MACD  \\\n",
      "Datetime                                                                        \n",
      "2025-02-07 16:30:00  230.302418  236.916003  230.873983  231.398040 -0.524057   \n",
      "2025-02-07 17:30:00  230.282594  236.790348  230.631663  231.242548 -0.610885   \n",
      "2025-02-07 18:30:00  230.258803  236.660148  230.208331  230.993471 -0.785140   \n",
      "2025-02-07 19:30:00  230.239703  236.528673  229.868588  230.771732 -0.903145   \n",
      "2025-02-07 20:30:00  230.225004  236.395523  229.536498  230.544938 -1.008439   \n",
      "\n",
      "                     MACD_Signal  MACD_Histogram  avg_sentiment  \n",
      "Datetime                                                         \n",
      "2025-02-07 16:30:00    -0.339885       -0.184172            0.0  \n",
      "2025-02-07 17:30:00    -0.394085       -0.216800            0.0  \n",
      "2025-02-07 18:30:00    -0.472296       -0.312844            0.0  \n",
      "2025-02-07 19:30:00    -0.558466       -0.344679            0.0  \n",
      "2025-02-07 20:30:00    -0.648460       -0.359979            0.0  \n",
      "Data shape: (2263, 16)\n",
      "\n",
      "Saved AAPL data with sentiment to stock_data\\AAPL_data_with_sentiment.csv\n",
      "[DEBUG] GOOG stock data shape: (2462, 17), columns: ['Close', 'High_GOOG', 'Low_GOOG', 'Open_GOOG', 'Volume_GOOG', 'SMA20', 'SMA44', 'SMA50', 'SMA100', 'SMA200', 'EMA12', 'EMA26', 'MACD', 'MACD_Signal', 'MACD_Histogram', 'Datetime', 'Date']\n",
      "Fetching up to 200 Reddit posts for GOOG in r/wallstreetbets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebert\\AppData\\Local\\Temp\\ipykernel_12172\\159500985.py:217: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df['avg_sentiment'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 200 posts for GOOG.\n",
      "[DEBUG] sentiment_daily shape: (163, 1), columns: ['avg_sentiment']\n",
      "\n",
      "--- Final merged DataFrame for GOOG ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2263 entries, 2023-10-12 16:30:00 to 2025-02-07 20:30:00\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Close           2263 non-null   float64\n",
      " 1   High_GOOG       2263 non-null   float64\n",
      " 2   Low_GOOG        2263 non-null   float64\n",
      " 3   Open_GOOG       2263 non-null   float64\n",
      " 4   Volume_GOOG     2263 non-null   int64  \n",
      " 5   SMA20           2263 non-null   float64\n",
      " 6   SMA44           2263 non-null   float64\n",
      " 7   SMA50           2263 non-null   float64\n",
      " 8   SMA100          2263 non-null   float64\n",
      " 9   SMA200          2263 non-null   float64\n",
      " 10  EMA12           2263 non-null   float64\n",
      " 11  EMA26           2263 non-null   float64\n",
      " 12  MACD            2263 non-null   float64\n",
      " 13  MACD_Signal     2263 non-null   float64\n",
      " 14  MACD_Histogram  2263 non-null   float64\n",
      " 15  avg_sentiment   2263 non-null   float64\n",
      "dtypes: float64(15), int64(1)\n",
      "memory usage: 300.6 KB\n",
      "None\n",
      "                          Close   High_GOOG    Low_GOOG   Open_GOOG  \\\n",
      "Datetime                                                              \n",
      "2023-10-12 16:30:00  140.279999  141.800003  140.009995  141.800003   \n",
      "2023-10-12 17:30:00  140.160004  140.460007  139.449997  140.270004   \n",
      "2023-10-12 18:30:00  140.479996  140.720001  140.009995  140.149994   \n",
      "2023-10-12 19:30:00  140.279999  140.690002  140.119995  140.470001   \n",
      "2023-10-13 13:30:00  140.080002  141.339996  139.854996  140.649994   \n",
      "\n",
      "                     Volume_GOOG       SMA20       SMA44       SMA50  \\\n",
      "Datetime                                                               \n",
      "2023-10-12 16:30:00      2397525  140.614090  138.763240  138.178456   \n",
      "2023-10-12 17:30:00      2127386  140.639590  138.855329  138.304156   \n",
      "2023-10-12 18:30:00      1613460  140.687590  138.966238  138.447052   \n",
      "2023-10-12 19:30:00      2075036  140.738590  139.074875  138.591152   \n",
      "2023-10-13 13:30:00      3825151  140.736591  139.163056  138.726352   \n",
      "\n",
      "                         SMA100      SMA200       EMA12       EMA26      MACD  \\\n",
      "Datetime                                                                        \n",
      "2023-10-12 16:30:00  135.092959  135.902846  141.007011  140.103399  0.903611   \n",
      "2023-10-12 17:30:00  135.167759  135.917846  140.876702  140.107592  0.769110   \n",
      "2023-10-12 18:30:00  135.251809  135.935646  140.815670  140.135178  0.680493   \n",
      "2023-10-12 19:30:00  135.341209  135.952346  140.733259  140.145905  0.587354   \n",
      "2023-10-13 13:30:00  135.420409  135.970196  140.632758  140.141024  0.491735   \n",
      "\n",
      "                     MACD_Signal  MACD_Histogram  avg_sentiment  \n",
      "Datetime                                                         \n",
      "2023-10-12 16:30:00     1.044367       -0.140756            0.0  \n",
      "2023-10-12 17:30:00     0.989316       -0.220206            0.0  \n",
      "2023-10-12 18:30:00     0.927551       -0.247059            0.0  \n",
      "2023-10-12 19:30:00     0.859512       -0.272158            0.0  \n",
      "2023-10-13 13:30:00     0.785956       -0.294222            0.0  \n",
      "                          Close   High_GOOG    Low_GOOG   Open_GOOG  \\\n",
      "Datetime                                                              \n",
      "2025-02-07 16:30:00  185.445007  187.490005  185.110001  187.347504   \n",
      "2025-02-07 17:30:00  187.828506  187.839996  185.220001  185.440002   \n",
      "2025-02-07 18:30:00  187.369995  188.179993  186.869995  187.809998   \n",
      "2025-02-07 19:30:00  187.123703  187.789993  187.100006  187.369995   \n",
      "2025-02-07 20:30:00  187.190002  187.460007  186.899994  187.119995   \n",
      "\n",
      "                     Volume_GOOG       SMA20       SMA44       SMA50  \\\n",
      "Datetime                                                               \n",
      "2025-02-07 16:30:00      3875821  193.806129  199.645465  199.439779   \n",
      "2025-02-07 17:30:00      2476479  192.851805  199.339294  199.258149   \n",
      "2025-02-07 18:30:00      2290224  191.866305  199.027931  199.069649   \n",
      "2025-02-07 19:30:00      2085096  190.834490  198.702105  198.872923   \n",
      "2025-02-07 20:30:00      2508441  190.680490  198.365060  198.653923   \n",
      "\n",
      "                         SMA100      SMA200       EMA12       EMA26      MACD  \\\n",
      "Datetime                                                                        \n",
      "2025-02-07 16:30:00  199.133849  196.880101  191.183341  194.642942 -3.459601   \n",
      "2025-02-07 17:30:00  199.035134  196.844394  190.667213  194.138169 -3.470956   \n",
      "2025-02-07 18:30:00  198.932634  196.803294  190.159948  193.636823 -3.476874   \n",
      "2025-02-07 19:30:00  198.820972  196.759142  189.692834  193.154369 -3.461536   \n",
      "2025-02-07 20:30:00  198.717272  196.717192  189.307783  192.712564 -3.404782   \n",
      "\n",
      "                     MACD_Signal  MACD_Histogram  avg_sentiment  \n",
      "Datetime                                                         \n",
      "2025-02-07 16:30:00    -2.862579       -0.597022        -0.2411  \n",
      "2025-02-07 17:30:00    -2.984254       -0.486702        -0.2411  \n",
      "2025-02-07 18:30:00    -3.082778       -0.394096        -0.2411  \n",
      "2025-02-07 19:30:00    -3.158530       -0.303006        -0.2411  \n",
      "2025-02-07 20:30:00    -3.207780       -0.197001        -0.2411  \n",
      "Data shape: (2263, 16)\n",
      "\n",
      "Saved GOOG data with sentiment to stock_data\\GOOG_data_with_sentiment.csv\n",
      "[DEBUG] MSFT stock data shape: (2462, 17), columns: ['Close', 'High_MSFT', 'Low_MSFT', 'Open_MSFT', 'Volume_MSFT', 'SMA20', 'SMA44', 'SMA50', 'SMA100', 'SMA200', 'EMA12', 'EMA26', 'MACD', 'MACD_Signal', 'MACD_Histogram', 'Datetime', 'Date']\n",
      "Fetching up to 200 Reddit posts for MSFT in r/wallstreetbets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebert\\AppData\\Local\\Temp\\ipykernel_12172\\159500985.py:217: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df['avg_sentiment'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 200 posts for MSFT.\n",
      "[DEBUG] sentiment_daily shape: (169, 1), columns: ['avg_sentiment']\n",
      "\n",
      "--- Final merged DataFrame for MSFT ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2263 entries, 2023-10-12 16:30:00 to 2025-02-07 20:30:00\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Close           2263 non-null   float64\n",
      " 1   High_MSFT       2263 non-null   float64\n",
      " 2   Low_MSFT        2263 non-null   float64\n",
      " 3   Open_MSFT       2263 non-null   float64\n",
      " 4   Volume_MSFT     2263 non-null   int64  \n",
      " 5   SMA20           2263 non-null   float64\n",
      " 6   SMA44           2263 non-null   float64\n",
      " 7   SMA50           2263 non-null   float64\n",
      " 8   SMA100          2263 non-null   float64\n",
      " 9   SMA200          2263 non-null   float64\n",
      " 10  EMA12           2263 non-null   float64\n",
      " 11  EMA26           2263 non-null   float64\n",
      " 12  MACD            2263 non-null   float64\n",
      " 13  MACD_Signal     2263 non-null   float64\n",
      " 14  MACD_Histogram  2263 non-null   float64\n",
      " 15  avg_sentiment   2263 non-null   float64\n",
      "dtypes: float64(15), int64(1)\n",
      "memory usage: 300.6 KB\n",
      "None\n",
      "                          Close   High_MSFT    Low_MSFT   Open_MSFT  \\\n",
      "Datetime                                                              \n",
      "2023-10-12 16:30:00  330.890015  332.959991  329.760010  332.589996   \n",
      "2023-10-12 17:30:00  329.209991  331.070007  328.720001  330.859985   \n",
      "2023-10-12 18:30:00  330.757111  331.119995  329.029999  329.199890   \n",
      "2023-10-12 19:30:00  331.190002  331.670013  330.750000  330.760010   \n",
      "2023-10-13 13:30:00  331.575012  333.829987  331.114990  332.380005   \n",
      "\n",
      "                     Volume_MSFT       SMA20       SMA44       SMA50  \\\n",
      "Datetime                                                               \n",
      "2023-10-12 16:30:00      2590785  330.433224  325.949581  324.515646   \n",
      "2023-10-12 17:30:00      2228010  330.418724  326.199581  324.844846   \n",
      "2023-10-12 18:30:00      1431656  330.463580  326.507243  325.212874   \n",
      "2023-10-12 19:30:00      1922850  330.583830  326.825652  325.604673   \n",
      "2023-10-13 13:30:00      4214942  330.649081  327.113039  325.969174   \n",
      "\n",
      "                         SMA100      SMA200       EMA12       EMA26      MACD  \\\n",
      "Datetime                                                                        \n",
      "2023-10-12 16:30:00  319.855386  325.408665  331.135465  329.212042  1.923423   \n",
      "2023-10-12 17:30:00  319.950436  325.404265  330.839239  329.211890  1.627348   \n",
      "2023-10-12 18:30:00  320.075707  325.414900  330.826603  329.326351  1.500252   \n",
      "2023-10-12 19:30:00  320.213808  325.430300  330.882511  329.464399  1.418112   \n",
      "2023-10-13 13:30:00  320.342058  325.451575  330.989050  329.620741  1.368309   \n",
      "\n",
      "                     MACD_Signal  MACD_Histogram  avg_sentiment  \n",
      "Datetime                                                         \n",
      "2023-10-12 16:30:00     2.148737       -0.225314            0.0  \n",
      "2023-10-12 17:30:00     2.044459       -0.417111            0.0  \n",
      "2023-10-12 18:30:00     1.935618       -0.435365            0.0  \n",
      "2023-10-12 19:30:00     1.832116       -0.414005            0.0  \n",
      "2023-10-13 13:30:00     1.739355       -0.371046            0.0  \n",
      "                          Close   High_MSFT    Low_MSFT   Open_MSFT  \\\n",
      "Datetime                                                              \n",
      "2025-02-07 16:30:00  410.180115  411.660004  409.559998  411.359985   \n",
      "2025-02-07 17:30:00  410.709991  411.339996  410.179993  410.179993   \n",
      "2025-02-07 18:30:00  408.285004  411.141998  408.279999  410.694397   \n",
      "2025-02-07 19:30:00  408.875000  409.159912  408.100006  408.269989   \n",
      "2025-02-07 20:30:00  409.760010  410.350006  408.809998  408.859985   \n",
      "\n",
      "                     Volume_MSFT       SMA20       SMA44       SMA50  \\\n",
      "Datetime                                                               \n",
      "2025-02-07 16:30:00      2450726  413.646146  414.058350  416.984360   \n",
      "2025-02-07 17:30:00      1559172  413.556755  413.955168  416.326756   \n",
      "2025-02-07 18:30:00      1948018  413.373006  413.813816  415.632456   \n",
      "2025-02-07 19:30:00      1847588  413.201256  413.658248  414.968656   \n",
      "2025-02-07 20:30:00      2749459  413.113756  413.534385  414.264346   \n",
      "\n",
      "                         SMA100      SMA200       EMA12       EMA26      MACD  \\\n",
      "Datetime                                                                        \n",
      "2025-02-07 16:30:00  427.764086  426.512562  413.531966  414.595237 -1.063270   \n",
      "2025-02-07 17:30:00  427.572236  426.396212  413.097816  414.307441 -1.209624   \n",
      "2025-02-07 18:30:00  427.348586  426.261212  412.357384  413.861334 -1.503951   \n",
      "2025-02-07 19:30:00  427.117498  426.126937  411.821632  413.491976 -1.670344   \n",
      "2025-02-07 20:30:00  426.914074  426.005099  411.504460  413.215534 -1.711075   \n",
      "\n",
      "                     MACD_Signal  MACD_Histogram  avg_sentiment  \n",
      "Datetime                                                         \n",
      "2025-02-07 16:30:00    -1.028792       -0.034478            0.0  \n",
      "2025-02-07 17:30:00    -1.064958       -0.144666            0.0  \n",
      "2025-02-07 18:30:00    -1.152757       -0.351194            0.0  \n",
      "2025-02-07 19:30:00    -1.256274       -0.414070            0.0  \n",
      "2025-02-07 20:30:00    -1.347234       -0.363840            0.0  \n",
      "Data shape: (2263, 16)\n",
      "\n",
      "Saved MSFT data with sentiment to stock_data\\MSFT_data_with_sentiment.csv\n",
      "[DEBUG] AMZN stock data shape: (2462, 17), columns: ['Close', 'High_AMZN', 'Low_AMZN', 'Open_AMZN', 'Volume_AMZN', 'SMA20', 'SMA44', 'SMA50', 'SMA100', 'SMA200', 'EMA12', 'EMA26', 'MACD', 'MACD_Signal', 'MACD_Histogram', 'Datetime', 'Date']\n",
      "Fetching up to 200 Reddit posts for AMZN in r/wallstreetbets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebert\\AppData\\Local\\Temp\\ipykernel_12172\\159500985.py:217: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df['avg_sentiment'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 200 posts for AMZN.\n",
      "[DEBUG] sentiment_daily shape: (174, 1), columns: ['avg_sentiment']\n",
      "\n",
      "--- Final merged DataFrame for AMZN ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2263 entries, 2023-10-12 16:30:00 to 2025-02-07 20:30:00\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Close           2263 non-null   float64\n",
      " 1   High_AMZN       2263 non-null   float64\n",
      " 2   Low_AMZN        2263 non-null   float64\n",
      " 3   Open_AMZN       2263 non-null   float64\n",
      " 4   Volume_AMZN     2263 non-null   int64  \n",
      " 5   SMA20           2263 non-null   float64\n",
      " 6   SMA44           2263 non-null   float64\n",
      " 7   SMA50           2263 non-null   float64\n",
      " 8   SMA100          2263 non-null   float64\n",
      " 9   SMA200          2263 non-null   float64\n",
      " 10  EMA12           2263 non-null   float64\n",
      " 11  EMA26           2263 non-null   float64\n",
      " 12  MACD            2263 non-null   float64\n",
      " 13  MACD_Signal     2263 non-null   float64\n",
      " 14  MACD_Histogram  2263 non-null   float64\n",
      " 15  avg_sentiment   2263 non-null   float64\n",
      "dtypes: float64(15), int64(1)\n",
      "memory usage: 300.6 KB\n",
      "None\n",
      "                          Close   High_AMZN    Low_AMZN   Open_AMZN  \\\n",
      "Datetime                                                              \n",
      "2023-10-12 16:30:00  131.949997  134.479996  131.830002  134.290100   \n",
      "2023-10-12 17:30:00  131.608597  132.164993  131.229996  131.945007   \n",
      "2023-10-12 18:30:00  132.149994  132.339996  131.440002  131.600006   \n",
      "2023-10-12 19:30:00  132.339996  132.460007  132.119995  132.149994   \n",
      "2023-10-13 13:30:00  132.195206  133.314499  131.410004  132.979996   \n",
      "\n",
      "                     Volume_AMZN       SMA20       SMA44       SMA50  \\\n",
      "Datetime                                                               \n",
      "2023-10-12 16:30:00      7563829  130.673190  128.396441  128.014520   \n",
      "2023-10-12 17:30:00      5853044  130.834119  128.518909  128.144692   \n",
      "2023-10-12 18:30:00      4993560  131.027119  128.648909  128.295092   \n",
      "2023-10-12 19:30:00      4754280  131.158119  128.788909  128.453251   \n",
      "2023-10-13 13:30:00     10710060  131.247050  128.910618  128.601556   \n",
      "\n",
      "                         SMA100      SMA200       EMA12       EMA26      MACD  \\\n",
      "Datetime                                                                        \n",
      "2023-10-12 16:30:00  127.850086  133.218427  131.756354  130.321065  1.435290   \n",
      "2023-10-12 17:30:00  127.855272  133.182870  131.733622  130.416437  1.317185   \n",
      "2023-10-12 18:30:00  127.878572  133.154270  131.797680  130.544849  1.252831   \n",
      "2023-10-12 19:30:00  127.911072  133.129670  131.881113  130.677823  1.203290   \n",
      "2023-10-13 13:30:00  127.935001  133.105647  131.929435  130.790222  1.139213   \n",
      "\n",
      "                     MACD_Signal  MACD_Histogram  avg_sentiment  \n",
      "Datetime                                                         \n",
      "2023-10-12 16:30:00     1.204765        0.230524            0.0  \n",
      "2023-10-12 17:30:00     1.227249        0.089936            0.0  \n",
      "2023-10-12 18:30:00     1.232366        0.020465            0.0  \n",
      "2023-10-12 19:30:00     1.226550       -0.023260            0.0  \n",
      "2023-10-13 13:30:00     1.209083       -0.069870            0.0  \n",
      "                          Close   High_AMZN    Low_AMZN   Open_AMZN  \\\n",
      "Datetime                                                              \n",
      "2025-02-07 16:30:00  229.029999  229.889999  228.070007  229.130005   \n",
      "2025-02-07 17:30:00  230.330002  230.970001  228.929993  229.009995   \n",
      "2025-02-07 18:30:00  228.934998  230.990005  228.869995  230.320007   \n",
      "2025-02-07 19:30:00  228.899994  229.375000  228.630005  228.949997   \n",
      "2025-02-07 20:30:00  229.270004  230.039993  228.710007  228.884995   \n",
      "\n",
      "                     Volume_AMZN       SMA20       SMA44       SMA50  \\\n",
      "Datetime                                                               \n",
      "2025-02-07 16:30:00      6746854  236.744360  237.321269  237.306529   \n",
      "2025-02-07 17:30:00      5357940  236.153111  237.238541  237.143617   \n",
      "2025-02-07 18:30:00      4588232  235.511111  237.115246  236.969817   \n",
      "2025-02-07 19:30:00      4026561  234.851611  236.982973  236.813616   \n",
      "2025-02-07 20:30:00      8612009  234.449586  236.852746  236.639417   \n",
      "\n",
      "                         SMA100      SMA200       EMA12       EMA26      MACD  \\\n",
      "Datetime                                                                        \n",
      "2025-02-07 16:30:00  235.315634  228.926860  234.504342  236.191756 -1.687414   \n",
      "2025-02-07 17:30:00  235.365234  228.947277  233.862136  235.757552 -1.895416   \n",
      "2025-02-07 18:30:00  235.406584  228.964452  233.104114  235.252177 -2.148063   \n",
      "2025-02-07 19:30:00  235.439077  228.978377  232.457327  234.781645 -2.324319   \n",
      "2025-02-07 20:30:00  235.475027  228.999027  231.966969  234.373375 -2.406406   \n",
      "\n",
      "                     MACD_Signal  MACD_Histogram  avg_sentiment  \n",
      "Datetime                                                         \n",
      "2025-02-07 16:30:00    -0.671450       -1.015963         0.1406  \n",
      "2025-02-07 17:30:00    -0.916244       -0.979172         0.1406  \n",
      "2025-02-07 18:30:00    -1.162607       -0.985455         0.1406  \n",
      "2025-02-07 19:30:00    -1.394950       -0.929369         0.1406  \n",
      "2025-02-07 20:30:00    -1.597241       -0.809165         0.1406  \n",
      "Data shape: (2263, 16)\n",
      "\n",
      "Saved AMZN data with sentiment to stock_data\\AMZN_data_with_sentiment.csv\n",
      "[DEBUG] NVDA stock data shape: (2462, 17), columns: ['Close', 'High_NVDA', 'Low_NVDA', 'Open_NVDA', 'Volume_NVDA', 'SMA20', 'SMA44', 'SMA50', 'SMA100', 'SMA200', 'EMA12', 'EMA26', 'MACD', 'MACD_Signal', 'MACD_Histogram', 'Datetime', 'Date']\n",
      "Fetching up to 200 Reddit posts for NVDA in r/wallstreetbets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebert\\AppData\\Local\\Temp\\ipykernel_12172\\159500985.py:217: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df['avg_sentiment'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 200 posts for NVDA.\n",
      "[DEBUG] sentiment_daily shape: (145, 1), columns: ['avg_sentiment']\n",
      "\n",
      "--- Final merged DataFrame for NVDA ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2263 entries, 2023-10-12 16:30:00 to 2025-02-07 20:30:00\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Close           2263 non-null   float64\n",
      " 1   High_NVDA       2263 non-null   float64\n",
      " 2   Low_NVDA        2263 non-null   float64\n",
      " 3   Open_NVDA       2263 non-null   float64\n",
      " 4   Volume_NVDA     2263 non-null   int64  \n",
      " 5   SMA20           2263 non-null   float64\n",
      " 6   SMA44           2263 non-null   float64\n",
      " 7   SMA50           2263 non-null   float64\n",
      " 8   SMA100          2263 non-null   float64\n",
      " 9   SMA200          2263 non-null   float64\n",
      " 10  EMA12           2263 non-null   float64\n",
      " 11  EMA26           2263 non-null   float64\n",
      " 12  MACD            2263 non-null   float64\n",
      " 13  MACD_Signal     2263 non-null   float64\n",
      " 14  MACD_Histogram  2263 non-null   float64\n",
      " 15  avg_sentiment   2263 non-null   float64\n",
      "dtypes: float64(15), int64(1)\n",
      "memory usage: 300.6 KB\n",
      "None\n",
      "                          Close   High_NVDA    Low_NVDA   Open_NVDA  \\\n",
      "Datetime                                                              \n",
      "2023-10-12 16:30:00  469.279999  475.600006  468.369995  474.489990   \n",
      "2023-10-12 17:30:00  467.140015  470.159912  463.299988  469.200012   \n",
      "2023-10-12 18:30:00  468.700012  469.851105  466.520111  467.049988   \n",
      "2023-10-12 19:30:00  469.459991  470.600006  468.610107  468.660004   \n",
      "2023-10-13 13:30:00  465.899994  471.160004  465.410004  469.600006   \n",
      "\n",
      "                     Volume_NVDA       SMA20       SMA44       SMA50  \\\n",
      "Datetime                                                               \n",
      "2023-10-12 16:30:00      6729286  463.020718  454.416499  452.123761   \n",
      "2023-10-12 17:30:00      7317313  463.619218  455.063772  452.746261   \n",
      "2023-10-12 18:30:00      4792197  464.417719  455.801500  453.419189   \n",
      "2023-10-12 19:30:00      3456452  465.083218  456.560704  454.135989   \n",
      "2023-10-13 13:30:00      9190880  465.339468  457.165022  454.747189   \n",
      "\n",
      "                         SMA100      SMA200       EMA12       EMA26      MACD  \\\n",
      "Datetime                                                                        \n",
      "2023-10-12 16:30:00  440.687371  445.941952  466.961625  461.498275  5.463350   \n",
      "2023-10-12 17:30:00  441.169621  445.837552  466.989070  461.916182  5.072888   \n",
      "2023-10-12 18:30:00  441.690521  445.760303  467.252292  462.418688  4.833604   \n",
      "2023-10-12 19:30:00  442.231871  445.683303  467.591938  462.940266  4.651672   \n",
      "2023-10-13 13:30:00  442.704071  445.584003  467.331639  463.159505  4.172134   \n",
      "\n",
      "                     MACD_Signal  MACD_Histogram  avg_sentiment  \n",
      "Datetime                                                         \n",
      "2023-10-12 16:30:00     4.931180        0.532170            0.0  \n",
      "2023-10-12 17:30:00     4.959521        0.113366            0.0  \n",
      "2023-10-12 18:30:00     4.934338       -0.100734            0.0  \n",
      "2023-10-12 19:30:00     4.877805       -0.226133            0.0  \n",
      "2023-10-13 13:30:00     4.736670       -0.564537            0.0  \n",
      "                          Close   High_NVDA    Low_NVDA   Open_NVDA  \\\n",
      "Datetime                                                              \n",
      "2025-02-07 16:30:00  128.235001  129.059601  127.599998  128.699997   \n",
      "2025-02-07 17:30:00  129.255005  129.649994  128.020004  128.229996   \n",
      "2025-02-07 18:30:00  128.130005  129.429993  127.908798  129.259903   \n",
      "2025-02-07 19:30:00  128.948502  129.089905  127.970001  128.139999   \n",
      "2025-02-07 20:30:00  129.860001  130.000000  128.820007  128.945007   \n",
      "\n",
      "                     Volume_NVDA       SMA20       SMA44       SMA50  \\\n",
      "Datetime                                                               \n",
      "2025-02-07 16:30:00     27757064  125.073130  122.443634  122.390966   \n",
      "2025-02-07 17:30:00     17653887  125.570380  122.675459  122.516098   \n",
      "2025-02-07 18:30:00     16675456  126.053630  122.876369  122.646898   \n",
      "2025-02-07 19:30:00     16455557  126.567056  123.091675  122.807668   \n",
      "2025-02-07 20:30:00     21996032  126.944556  123.282698  122.941868   \n",
      "\n",
      "                         SMA100      SMA200       EMA12       EMA26      MACD  \\\n",
      "Datetime                                                                        \n",
      "2025-02-07 16:30:00  129.461859  133.962781  127.118579  125.113288  2.005291   \n",
      "2025-02-07 17:30:00  129.373117  133.919406  127.447260  125.420082  2.027178   \n",
      "2025-02-07 18:30:00  129.274732  133.867406  127.552297  125.620817  1.931481   \n",
      "2025-02-07 19:30:00  129.181617  133.815399  127.767098  125.867312  1.899786   \n",
      "2025-02-07 20:30:00  129.099317  133.769399  128.089083  126.163067  1.926017   \n",
      "\n",
      "                     MACD_Signal  MACD_Histogram  avg_sentiment  \n",
      "Datetime                                                         \n",
      "2025-02-07 16:30:00     1.634148        0.371143            0.0  \n",
      "2025-02-07 17:30:00     1.712754        0.314424            0.0  \n",
      "2025-02-07 18:30:00     1.756499        0.174981            0.0  \n",
      "2025-02-07 19:30:00     1.785157        0.114629            0.0  \n",
      "2025-02-07 20:30:00     1.813329        0.112688            0.0  \n",
      "Data shape: (2263, 16)\n",
      "\n",
      "Saved NVDA data with sentiment to stock_data\\NVDA_data_with_sentiment.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebert\\AppData\\Local\\Temp\\ipykernel_12172\\159500985.py:217: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df['avg_sentiment'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import praw\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Ensure the VADER lexicon is downloaded\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# --- Reddit API Credentials ---\n",
    "REDDIT_CLIENT_ID = \"VQ-NOvyPWyJvGZs1ifD0Ww\"\n",
    "REDDIT_CLIENT_SECRET = \"BX_Dlp6miv2eMo4qt5JY_imgYVyMBA\"\n",
    "REDDIT_USER_AGENT = \"StockSentimentAnalysis/0.1 by Joseph\"\n",
    "\n",
    "# Initialize the Reddit client (PRAW)\n",
    "reddit = praw.Reddit(\n",
    "    client_id=REDDIT_CLIENT_ID,\n",
    "    client_secret=REDDIT_CLIENT_SECRET,\n",
    "    user_agent=REDDIT_USER_AGENT\n",
    ")\n",
    "\n",
    "def fetch_intraday_chunks(ticker, start_date, end_date, interval=\"1h\", max_days=60):\n",
    "    \"\"\"\n",
    "    Fetch intraday data in chunks for a given ticker from start_date to end_date,\n",
    "    avoiding yfinance's ~60-day intraday limit by splitting the date range.\n",
    "    \n",
    "    Returns a single DataFrame for the entire period, with a single-level DatetimeIndex.\n",
    "    \"\"\"\n",
    "    start_dt = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end_dt = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    \n",
    "    all_data = []\n",
    "    current_start = start_dt\n",
    "\n",
    "    while current_start < end_dt:\n",
    "        current_end = current_start + timedelta(days=max_days)\n",
    "        if current_end > end_dt:\n",
    "            current_end = end_dt\n",
    "\n",
    "        chunk_start_str = current_start.strftime(\"%Y-%m-%d\")\n",
    "        chunk_end_str = current_end.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        print(f\"Fetching {ticker} data from {chunk_start_str} to {chunk_end_str} with {interval} interval...\")\n",
    "        chunk_data = yf.download(ticker, start=chunk_start_str, end=chunk_end_str, interval=interval)\n",
    "        \n",
    "        if not chunk_data.empty:\n",
    "            all_data.append(chunk_data)\n",
    "        else:\n",
    "            print(f\"No data returned for {ticker} from {chunk_start_str} to {chunk_end_str}.\")\n",
    "        \n",
    "        current_start = current_end + timedelta(days=1)\n",
    "    \n",
    "    if all_data:\n",
    "        full_data = pd.concat(all_data)\n",
    "        full_data.sort_index(inplace=True)\n",
    "        \n",
    "        # Ensure index is a proper DatetimeIndex\n",
    "        if not pd.api.types.is_datetime64_any_dtype(full_data.index):\n",
    "            print(\"[DEBUG] Converting index to datetime...\")\n",
    "            full_data.index = pd.to_datetime(full_data.index, errors='coerce')\n",
    "        \n",
    "        # Flatten multi-level columns if needed\n",
    "        if isinstance(full_data.columns, pd.MultiIndex):\n",
    "            full_data.columns = [\n",
    "                \"_\".join(col) if isinstance(col, tuple) else col\n",
    "                for col in full_data.columns\n",
    "            ]\n",
    "        \n",
    "        # Drop top level if we have a multi-level index (e.g., (ticker, datetime))\n",
    "        if full_data.index.nlevels > 1:\n",
    "            print(\"[DEBUG] Dropping the top index level...\")\n",
    "            full_data.index = full_data.index.droplevel(0)\n",
    "        \n",
    "        return full_data\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "def add_time_features(data):\n",
    "    \"\"\"\n",
    "    Add time-based features to the DataFrame:\n",
    "      - 'Hour': extracts the hour from the index.\n",
    "      - 'HourlyCandleCount': counts the candle number within each day.\n",
    "    \"\"\"\n",
    "    if not data.empty:\n",
    "        # Extract hour from the DatetimeIndex\n",
    "        data['Hour'] = data.index.hour\n",
    "        # Count the hourly candle for each day (starting at 1)\n",
    "        data['HourlyCandleCount'] = data.groupby(data.index.date).cumcount() + 1\n",
    "    return data\n",
    "    \n",
    "def add_indicators(data, sma_windows=[20, 44, 50, 100, 200]):\n",
    "    \"\"\"\n",
    "    Calculate technical indicators and add them as new columns to the DataFrame.\n",
    "    \n",
    "    Calculates:\n",
    "      - SMA (Simple Moving Average) for each window in sma_windows.\n",
    "      - MACD components (MACD line, Signal line, and Histogram).\n",
    "      \n",
    "    Parameters:\n",
    "        data (DataFrame): DataFrame containing stock data.\n",
    "        sma_windows (list): List of window periods for SMA calculation.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: DataFrame with additional indicator columns.\n",
    "    \"\"\"\n",
    "    data.rename(columns=lambda x: \"Close\" if \"Close\" in x else x, inplace=True)\n",
    "    if not data.empty and \"Close\" in data.columns:\n",
    "        # Calculate SMAs for each specified window\n",
    "        for window in sma_windows:\n",
    "            data[f'SMA{window}'] = data['Close'].rolling(window=window).mean()\n",
    "        \n",
    "        # Calculate MACD components:\n",
    "        # 12-period EMA and 26-period EMA\n",
    "        data['EMA12'] = data['Close'].ewm(span=12, adjust=False).mean()\n",
    "        data['EMA26'] = data['Close'].ewm(span=26, adjust=False).mean()\n",
    "        # MACD Line\n",
    "        data['MACD'] = data['EMA12'] - data['EMA26']\n",
    "        # Signal Line: 9-period EMA of MACD\n",
    "        data['MACD_Signal'] = data['MACD'].ewm(span=9, adjust=False).mean()\n",
    "        # Histogram: MACD - Signal Line\n",
    "        data['MACD_Histogram'] = data['MACD'] - data['MACD_Signal']\n",
    "        \n",
    "        # Debug: print the columns to verify technical indicators are added\n",
    "        print(\"[DEBUG] Technical indicator columns added:\", data.columns.tolist())\n",
    "    return data\n",
    "\n",
    "def get_stocks_data(ticker_list, start_date, end_date, interval=\"1h\", max_days=60):\n",
    "    \"\"\"\n",
    "    Fetch historical intraday stock data for each ticker over a large date range by chunking.\n",
    "    Returns a dictionary {ticker: DataFrame}.\n",
    "    \"\"\"\n",
    "    stocks_data = {}\n",
    "    for ticker in ticker_list:\n",
    "        data = fetch_intraday_chunks(ticker, start_date, end_date, interval, max_days)\n",
    "        # Add SMA and MACD technical indicators\n",
    "        data = add_indicators(data, sma_windows=[20, 44, 50, 100, 200])\n",
    "        # Add time features\n",
    "        data = add_time_features(data)\n",
    "        stocks_data[ticker] = data\n",
    "    return stocks_data\n",
    "\n",
    "def fetch_reddit_posts(ticker, limit=200, subreddit=\"wallstreetbets\"):\n",
    "    \"\"\"\n",
    "    Fetch up to 'limit' Reddit posts from a subreddit that mention the ticker.\n",
    "    (PRAW doesn't allow date-based filtering, so we do a broad search and later\n",
    "    aggregate by date in Python.)\n",
    "    \n",
    "    Returns: list of dict, each with {'created': datetime, 'text': ...}\n",
    "    \"\"\"\n",
    "    print(f\"Fetching up to {limit} Reddit posts for {ticker} in r/{subreddit}...\")\n",
    "    posts = []\n",
    "    try:\n",
    "        for submission in reddit.subreddit(subreddit).search(ticker, limit=limit):\n",
    "            created_dt = pd.to_datetime(submission.created_utc, unit='s', utc=True)\n",
    "            created_dt = created_dt.tz_localize(None)\n",
    "            text = f\"{submission.title} {submission.selftext}\"\n",
    "            posts.append({'created': created_dt, 'text': text})\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching Reddit posts: {e}\")\n",
    "    print(f\"Fetched {len(posts)} posts for {ticker}.\")\n",
    "    return posts\n",
    "\n",
    "def analyze_sentiment(posts):\n",
    "    \"\"\"\n",
    "    Perform VADER sentiment analysis on each post.\n",
    "    Returns a DataFrame with columns ['created', 'compound'].\n",
    "    \"\"\"\n",
    "    if not posts:\n",
    "        return pd.DataFrame(columns=[\"created\", \"compound\"])\n",
    "    \n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    results = []\n",
    "    for p in posts:\n",
    "        scores = sid.polarity_scores(p['text'])\n",
    "        results.append({\n",
    "            'created': p['created'],\n",
    "            'compound': scores['compound']\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def aggregate_sentiment_by_date(sentiment_df):\n",
    "    \"\"\"\n",
    "    Convert each post's 'created' datetime to a date, then average the 'compound' score by date.\n",
    "    Returns a DataFrame indexed by 'Date' with column 'avg_sentiment'.\n",
    "    \"\"\"\n",
    "    if sentiment_df.empty:\n",
    "        return pd.DataFrame(columns=[\"avg_sentiment\"])\n",
    "    \n",
    "    sentiment_df['Date'] = sentiment_df['created'].dt.date\n",
    "    grouped = sentiment_df.groupby('Date')['compound'].mean().reset_index()\n",
    "    grouped.rename(columns={'compound': 'avg_sentiment'}, inplace=True)\n",
    "    grouped.set_index('Date', inplace=True)\n",
    "    return grouped\n",
    "\n",
    "def merge_stock_with_sentiment(stock_df, ticker):\n",
    "    \"\"\"\n",
    "    1) Store original intraday index in 'Datetime' column\n",
    "    2) Create a 'Date' column from that intraday index\n",
    "    3) Reset the index to a RangeIndex\n",
    "    4) Fetch & analyze Reddit posts for 'ticker'\n",
    "    5) Aggregate sentiment by date\n",
    "    6) Merge on 'Date'\n",
    "    7) Restore the original intraday index as row labels\n",
    "    8) Return a DataFrame with 'avg_sentiment'\n",
    "    \"\"\"\n",
    "    if stock_df.empty:\n",
    "        return stock_df\n",
    "    \n",
    "    # 1) Store original intraday index in a new column\n",
    "    stock_df['Datetime'] = stock_df.index\n",
    "    \n",
    "    # 2) Create a 'Date' column from that intraday index\n",
    "    stock_df['Date'] = stock_df.index.date\n",
    "    \n",
    "    # 3) Reset the index\n",
    "    stock_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    print(f\"[DEBUG] {ticker} stock data shape: {stock_df.shape}, columns: {stock_df.columns.tolist()}\")\n",
    "\n",
    "    # 4) Fetch & analyze Reddit posts\n",
    "    posts = fetch_reddit_posts(ticker, limit=200)\n",
    "    sentiment_df = analyze_sentiment(posts)\n",
    "    sentiment_daily = aggregate_sentiment_by_date(sentiment_df)\n",
    "    \n",
    "    print(f\"[DEBUG] sentiment_daily shape: {sentiment_daily.shape}, columns: {sentiment_daily.columns.tolist()}\")\n",
    "    \n",
    "    # 5) Merge on 'Date'\n",
    "    merged_df = stock_df.merge(sentiment_daily, how='left', left_on='Date', right_on='Date')\n",
    "    merged_df['avg_sentiment'].fillna(0, inplace=True)\n",
    "    \n",
    "    # 7) Restore the original intraday timestamps as row labels\n",
    "    #    We'll set the index to 'Datetime'\n",
    "    merged_df.set_index('Datetime', inplace=True)\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "def save_stocks_to_csv(stocks_data, output_dir=\".\"):\n",
    "    \"\"\"\n",
    "    For each ticker:\n",
    "      1) Merge the chunked stock data with Reddit sentiment\n",
    "      2) Print the final merged DataFrame\n",
    "      3) Save to CSV\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    for ticker, data in stocks_data.items():\n",
    "        if data.empty:\n",
    "            print(f\"No data for {ticker}; skipping sentiment merge and CSV save.\")\n",
    "            continue\n",
    "        \n",
    "        merged_df = merge_stock_with_sentiment(data, ticker)\n",
    "        \n",
    "        print(f\"\\n--- Final merged DataFrame for {ticker} ---\")\n",
    "        print(merged_df.info())\n",
    "        print(merged_df.head(5))\n",
    "        print(merged_df.tail(5))\n",
    "        print(f\"Data shape: {merged_df.shape}\\n\")\n",
    "        \n",
    "        file_path = os.path.join(output_dir, f\"{ticker}_data_with_sentiment.csv\")\n",
    "        merged_df.to_csv(file_path)\n",
    "        print(f\"Saved {ticker} data with sentiment to {file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tickers = [\"AAPL\", \"GOOG\", \"MSFT\", \"AMZN\", \"NVDA\"]\n",
    "    start_date = \"2023-01-01\"\n",
    "    end_date = \"2025-02-10\"\n",
    "    \n",
    "    stocks_data = get_stocks_data(tickers, start_date, end_date, interval=\"1h\", max_days=60)\n",
    "    save_stocks_to_csv(stocks_data, output_dir=\"stock_data\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
