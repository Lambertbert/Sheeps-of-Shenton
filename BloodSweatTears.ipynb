{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.54)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (2.0.2)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (2.32.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\sebert\\appdata\\roaming\\python\\python312\\site-packages (from yfinance) (4.3.6)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (2025.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (3.17.9)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (4.13.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sebert\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31->yfinance) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31->yfinance) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31->yfinance) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31->yfinance) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sebert\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (7.8.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: nltk in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: prawcore<3,>=2.4 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from praw) (2.4.0)\n",
      "Requirement already satisfied: update_checker>=0.18 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from praw) (1.8.0)\n",
      "Requirement already satisfied: click in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sebert\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from prawcore<3,>=2.4->praw) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sebert\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sebert\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sebert\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install praw nltk pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Sebert\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Sebert\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching AAPL data from 2023-01-01 to 2023-03-02 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['AAPL']: YFPricesMissingError('possibly delisted; no price data found  (1h 2023-01-01 -> 2023-03-02) (Yahoo error = \"1h data not available for startTime=1672549200 and endTime=1677733200. The requested range must be within the last 730 days.\")')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data returned for AAPL from 2023-01-01 to 2023-03-02.\n",
      "Fetching AAPL data from 2023-03-03 to 2023-05-02 with 1h interval...\n",
      "Fetching AAPL data from 2023-05-03 to 2023-07-02 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching AAPL data from 2023-07-03 to 2023-09-01 with 1h interval...\n",
      "Fetching AAPL data from 2023-09-02 to 2023-11-01 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching AAPL data from 2023-11-02 to 2024-01-01 with 1h interval...\n",
      "Fetching AAPL data from 2024-01-02 to 2024-03-02 with 1h interval...\n",
      "Fetching AAPL data from 2024-03-03 to 2024-05-02 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching AAPL data from 2024-05-03 to 2024-07-02 with 1h interval...\n",
      "Fetching AAPL data from 2024-07-03 to 2024-09-01 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching AAPL data from 2024-09-02 to 2024-11-01 with 1h interval...\n",
      "Fetching AAPL data from 2024-11-02 to 2025-01-01 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching AAPL data from 2025-01-02 to 2025-02-10 with 1h interval...\n",
      "[DEBUG] Technical indicator columns added: ['Close', 'High_AAPL', 'Low_AAPL', 'Open_AAPL', 'Volume_AAPL', 'SMA20', 'SMA44', 'SMA50', 'SMA100', 'SMA200', 'EMA12', 'EMA26', 'MACD', 'MACD_Signal', 'MACD_Histogram']\n",
      "Fetching GOOG data from 2023-01-01 to 2023-03-02 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['GOOG']: YFPricesMissingError('possibly delisted; no price data found  (1h 2023-01-01 -> 2023-03-02) (Yahoo error = \"1h data not available for startTime=1672549200 and endTime=1677733200. The requested range must be within the last 730 days.\")')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data returned for GOOG from 2023-01-01 to 2023-03-02.\n",
      "Fetching GOOG data from 2023-03-03 to 2023-05-02 with 1h interval...\n",
      "Fetching GOOG data from 2023-05-03 to 2023-07-02 with 1h interval...\n",
      "Fetching GOOG data from 2023-07-03 to 2023-09-01 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching GOOG data from 2023-09-02 to 2023-11-01 with 1h interval...\n",
      "Fetching GOOG data from 2023-11-02 to 2024-01-01 with 1h interval...\n",
      "Fetching GOOG data from 2024-01-02 to 2024-03-02 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching GOOG data from 2024-03-03 to 2024-05-02 with 1h interval...\n",
      "Fetching GOOG data from 2024-05-03 to 2024-07-02 with 1h interval...\n",
      "Fetching GOOG data from 2024-07-03 to 2024-09-01 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching GOOG data from 2024-09-02 to 2024-11-01 with 1h interval...\n",
      "Fetching GOOG data from 2024-11-02 to 2025-01-01 with 1h interval...\n",
      "Fetching GOOG data from 2025-01-02 to 2025-02-10 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Technical indicator columns added: ['Close', 'High_GOOG', 'Low_GOOG', 'Open_GOOG', 'Volume_GOOG', 'SMA20', 'SMA44', 'SMA50', 'SMA100', 'SMA200', 'EMA12', 'EMA26', 'MACD', 'MACD_Signal', 'MACD_Histogram']\n",
      "Fetching MSFT data from 2023-01-01 to 2023-03-02 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['MSFT']: YFPricesMissingError('possibly delisted; no price data found  (1h 2023-01-01 -> 2023-03-02) (Yahoo error = \"1h data not available for startTime=1672549200 and endTime=1677733200. The requested range must be within the last 730 days.\")')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data returned for MSFT from 2023-01-01 to 2023-03-02.\n",
      "Fetching MSFT data from 2023-03-03 to 2023-05-02 with 1h interval...\n",
      "Fetching MSFT data from 2023-05-03 to 2023-07-02 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching MSFT data from 2023-07-03 to 2023-09-01 with 1h interval...\n",
      "Fetching MSFT data from 2023-09-02 to 2023-11-01 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching MSFT data from 2023-11-02 to 2024-01-01 with 1h interval...\n",
      "Fetching MSFT data from 2024-01-02 to 2024-03-02 with 1h interval...\n",
      "Fetching MSFT data from 2024-03-03 to 2024-05-02 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching MSFT data from 2024-05-03 to 2024-07-02 with 1h interval...\n",
      "Fetching MSFT data from 2024-07-03 to 2024-09-01 with 1h interval...\n",
      "Fetching MSFT data from 2024-09-02 to 2024-11-01 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching MSFT data from 2024-11-02 to 2025-01-01 with 1h interval...\n",
      "Fetching MSFT data from 2025-01-02 to 2025-02-10 with 1h interval...\n",
      "[DEBUG] Technical indicator columns added: ['Close', 'High_MSFT', 'Low_MSFT', 'Open_MSFT', 'Volume_MSFT', 'SMA20', 'SMA44', 'SMA50', 'SMA100', 'SMA200', 'EMA12', 'EMA26', 'MACD', 'MACD_Signal', 'MACD_Histogram']\n",
      "Fetching AMZN data from 2023-01-01 to 2023-03-02 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['AMZN']: YFPricesMissingError('possibly delisted; no price data found  (1h 2023-01-01 -> 2023-03-02) (Yahoo error = \"1h data not available for startTime=1672549200 and endTime=1677733200. The requested range must be within the last 730 days.\")')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data returned for AMZN from 2023-01-01 to 2023-03-02.\n",
      "Fetching AMZN data from 2023-03-03 to 2023-05-02 with 1h interval...\n",
      "Fetching AMZN data from 2023-05-03 to 2023-07-02 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching AMZN data from 2023-07-03 to 2023-09-01 with 1h interval...\n",
      "Fetching AMZN data from 2023-09-02 to 2023-11-01 with 1h interval...\n",
      "Fetching AMZN data from 2023-11-02 to 2024-01-01 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching AMZN data from 2024-01-02 to 2024-03-02 with 1h interval...\n",
      "Fetching AMZN data from 2024-03-03 to 2024-05-02 with 1h interval...\n",
      "Fetching AMZN data from 2024-05-03 to 2024-07-02 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching AMZN data from 2024-07-03 to 2024-09-01 with 1h interval...\n",
      "Fetching AMZN data from 2024-09-02 to 2024-11-01 with 1h interval...\n",
      "Fetching AMZN data from 2024-11-02 to 2025-01-01 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching AMZN data from 2025-01-02 to 2025-02-10 with 1h interval...\n",
      "[DEBUG] Technical indicator columns added: ['Close', 'High_AMZN', 'Low_AMZN', 'Open_AMZN', 'Volume_AMZN', 'SMA20', 'SMA44', 'SMA50', 'SMA100', 'SMA200', 'EMA12', 'EMA26', 'MACD', 'MACD_Signal', 'MACD_Histogram']\n",
      "Fetching NVDA data from 2023-01-01 to 2023-03-02 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['NVDA']: YFPricesMissingError('possibly delisted; no price data found  (1h 2023-01-01 -> 2023-03-02) (Yahoo error = \"1h data not available for startTime=1672549200 and endTime=1677733200. The requested range must be within the last 730 days.\")')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data returned for NVDA from 2023-01-01 to 2023-03-02.\n",
      "Fetching NVDA data from 2023-03-03 to 2023-05-02 with 1h interval...\n",
      "Fetching NVDA data from 2023-05-03 to 2023-07-02 with 1h interval...\n",
      "Fetching NVDA data from 2023-07-03 to 2023-09-01 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching NVDA data from 2023-09-02 to 2023-11-01 with 1h interval...\n",
      "Fetching NVDA data from 2023-11-02 to 2024-01-01 with 1h interval...\n",
      "Fetching NVDA data from 2024-01-02 to 2024-03-02 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching NVDA data from 2024-03-03 to 2024-05-02 with 1h interval...\n",
      "Fetching NVDA data from 2024-05-03 to 2024-07-02 with 1h interval...\n",
      "Fetching NVDA data from 2024-07-03 to 2024-09-01 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching NVDA data from 2024-09-02 to 2024-11-01 with 1h interval...\n",
      "Fetching NVDA data from 2024-11-02 to 2025-01-01 with 1h interval...\n",
      "Fetching NVDA data from 2025-01-02 to 2025-02-10 with 1h interval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Technical indicator columns added: ['Close', 'High_NVDA', 'Low_NVDA', 'Open_NVDA', 'Volume_NVDA', 'SMA20', 'SMA44', 'SMA50', 'SMA100', 'SMA200', 'EMA12', 'EMA26', 'MACD', 'MACD_Signal', 'MACD_Histogram']\n",
      "[DEBUG] AAPL stock data shape: (3340, 17), columns: ['Close', 'High_AAPL', 'Low_AAPL', 'Open_AAPL', 'Volume_AAPL', 'SMA20', 'SMA44', 'SMA50', 'SMA100', 'SMA200', 'EMA12', 'EMA26', 'MACD', 'MACD_Signal', 'MACD_Histogram', 'Datetime', 'Date']\n",
      "Fetching up to 200 Reddit posts for AAPL in r/wallstreetbets...\n",
      "Fetched 200 posts for AAPL.\n",
      "[DEBUG] sentiment_daily shape: (177, 1), columns: ['avg_sentiment']\n",
      "\n",
      "--- Final merged DataFrame for AAPL ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3340 entries, 2023-03-03 14:30:00+00:00 to 2025-02-07 20:30:00+00:00\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Close           3340 non-null   float64\n",
      " 1   High_AAPL       3340 non-null   float64\n",
      " 2   Low_AAPL        3340 non-null   float64\n",
      " 3   Open_AAPL       3340 non-null   float64\n",
      " 4   Volume_AAPL     3340 non-null   int64  \n",
      " 5   SMA20           3321 non-null   float64\n",
      " 6   SMA44           3297 non-null   float64\n",
      " 7   SMA50           3291 non-null   float64\n",
      " 8   SMA100          3241 non-null   float64\n",
      " 9   SMA200          3141 non-null   float64\n",
      " 10  EMA12           3340 non-null   float64\n",
      " 11  EMA26           3340 non-null   float64\n",
      " 12  MACD            3340 non-null   float64\n",
      " 13  MACD_Signal     3340 non-null   float64\n",
      " 14  MACD_Histogram  3340 non-null   float64\n",
      " 15  avg_sentiment   3340 non-null   float64\n",
      "dtypes: float64(15), int64(1)\n",
      "memory usage: 443.6 KB\n",
      "None\n",
      "                                Close   High_AAPL    Low_AAPL   Open_AAPL  \\\n",
      "Datetime                                                                    \n",
      "2023-03-03 14:30:00+00:00  150.149994  150.160004  147.449997  147.629898   \n",
      "2023-03-03 15:30:00+00:00  149.570007  150.169998  149.375000  150.139999   \n",
      "2023-03-03 16:30:00+00:00  149.914200  150.029999  149.259995  149.574997   \n",
      "2023-03-03 17:30:00+00:00  150.101395  150.320007  149.600098  149.914993   \n",
      "2023-03-03 18:30:00+00:00  150.759995  150.809998  149.910004  150.104996   \n",
      "\n",
      "                           Volume_AAPL  SMA20  SMA44  SMA50  SMA100  SMA200  \\\n",
      "Datetime                                                                      \n",
      "2023-03-03 14:30:00+00:00     18325087    NaN    NaN    NaN     NaN     NaN   \n",
      "2023-03-03 15:30:00+00:00      7392346    NaN    NaN    NaN     NaN     NaN   \n",
      "2023-03-03 16:30:00+00:00      6663071    NaN    NaN    NaN     NaN     NaN   \n",
      "2023-03-03 17:30:00+00:00      6588836    NaN    NaN    NaN     NaN     NaN   \n",
      "2023-03-03 18:30:00+00:00      5696300    NaN    NaN    NaN     NaN     NaN   \n",
      "\n",
      "                                EMA12       EMA26      MACD  MACD_Signal  \\\n",
      "Datetime                                                                   \n",
      "2023-03-03 14:30:00+00:00  150.149994  150.149994  0.000000     0.000000   \n",
      "2023-03-03 15:30:00+00:00  150.060765  150.107032 -0.046267    -0.009253   \n",
      "2023-03-03 16:30:00+00:00  150.038217  150.092748 -0.054531    -0.018309   \n",
      "2023-03-03 17:30:00+00:00  150.047936  150.093389 -0.045452    -0.023738   \n",
      "2023-03-03 18:30:00+00:00  150.157484  150.142767  0.014717    -0.016047   \n",
      "\n",
      "                           MACD_Histogram  avg_sentiment  \n",
      "Datetime                                                  \n",
      "2023-03-03 14:30:00+00:00        0.000000            0.0  \n",
      "2023-03-03 15:30:00+00:00       -0.037013            0.0  \n",
      "2023-03-03 16:30:00+00:00       -0.036222            0.0  \n",
      "2023-03-03 17:30:00+00:00       -0.021715            0.0  \n",
      "2023-03-03 18:30:00+00:00        0.030764            0.0  \n",
      "                                Close   High_AAPL    Low_AAPL   Open_AAPL  \\\n",
      "Datetime                                                                    \n",
      "2025-02-07 16:30:00+00:00  228.400604  229.419998  228.195007  229.085007   \n",
      "2025-02-07 17:30:00+00:00  229.298904  229.440002  228.363297  228.389999   \n",
      "2025-02-07 18:30:00+00:00  227.880005  229.500000  227.830002  229.289993   \n",
      "2025-02-07 19:30:00+00:00  228.000000  228.580002  227.789993  227.889999   \n",
      "2025-02-07 20:30:00+00:00  227.710007  228.149994  227.259995  227.990005   \n",
      "\n",
      "                           Volume_AAPL       SMA20       SMA44       SMA50  \\\n",
      "Datetime                                                                     \n",
      "2025-02-07 16:30:00+00:00      3763438  231.256165  232.656043  233.289398   \n",
      "2025-02-07 17:30:00+00:00      3721234  231.114110  232.454654  233.137996   \n",
      "2025-02-07 18:30:00+00:00      2602577  230.892660  232.223972  232.946996   \n",
      "2025-02-07 19:30:00+00:00      2965606  230.653160  231.986472  232.778096   \n",
      "2025-02-07 20:30:00+00:00      5030649  230.563660  231.724200  232.551296   \n",
      "\n",
      "                               SMA100      SMA200       EMA12       EMA26  \\\n",
      "Datetime                                                                    \n",
      "2025-02-07 16:30:00+00:00  230.302418  236.753509  230.873983  231.398037   \n",
      "2025-02-07 17:30:00+00:00  230.282594  236.613203  230.631663  231.242546   \n",
      "2025-02-07 18:30:00+00:00  230.258803  236.460797  230.208331  230.993468   \n",
      "2025-02-07 19:30:00+00:00  230.239703  236.306397  229.868588  230.771730   \n",
      "2025-02-07 20:30:00+00:00  230.225004  236.150023  229.536498  230.544936   \n",
      "\n",
      "                               MACD  MACD_Signal  MACD_Histogram  \\\n",
      "Datetime                                                           \n",
      "2025-02-07 16:30:00+00:00 -0.524054    -0.339880       -0.184174   \n",
      "2025-02-07 17:30:00+00:00 -0.610882    -0.394081       -0.216802   \n",
      "2025-02-07 18:30:00+00:00 -0.785137    -0.472292       -0.312845   \n",
      "2025-02-07 19:30:00+00:00 -0.903142    -0.558462       -0.344680   \n",
      "2025-02-07 20:30:00+00:00 -1.008437    -0.648457       -0.359980   \n",
      "\n",
      "                           avg_sentiment  \n",
      "Datetime                                  \n",
      "2025-02-07 16:30:00+00:00            0.0  \n",
      "2025-02-07 17:30:00+00:00            0.0  \n",
      "2025-02-07 18:30:00+00:00            0.0  \n",
      "2025-02-07 19:30:00+00:00            0.0  \n",
      "2025-02-07 20:30:00+00:00            0.0  \n",
      "Data shape: (3340, 16)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebert\\AppData\\Local\\Temp\\ipykernel_23380\\1712123349.py:218: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df['avg_sentiment'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved AAPL data with sentiment to stock_data\\AAPL_data_with_sentiment.csv\n",
      "[DEBUG] GOOG stock data shape: (3340, 17), columns: ['Close', 'High_GOOG', 'Low_GOOG', 'Open_GOOG', 'Volume_GOOG', 'SMA20', 'SMA44', 'SMA50', 'SMA100', 'SMA200', 'EMA12', 'EMA26', 'MACD', 'MACD_Signal', 'MACD_Histogram', 'Datetime', 'Date']\n",
      "Fetching up to 200 Reddit posts for GOOG in r/wallstreetbets...\n",
      "Fetched 200 posts for GOOG.\n",
      "[DEBUG] sentiment_daily shape: (164, 1), columns: ['avg_sentiment']\n",
      "\n",
      "--- Final merged DataFrame for GOOG ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3340 entries, 2023-03-03 14:30:00+00:00 to 2025-02-07 20:30:00+00:00\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Close           3340 non-null   float64\n",
      " 1   High_GOOG       3340 non-null   float64\n",
      " 2   Low_GOOG        3340 non-null   float64\n",
      " 3   Open_GOOG       3340 non-null   float64\n",
      " 4   Volume_GOOG     3340 non-null   int64  \n",
      " 5   SMA20           3321 non-null   float64\n",
      " 6   SMA44           3297 non-null   float64\n",
      " 7   SMA50           3291 non-null   float64\n",
      " 8   SMA100          3241 non-null   float64\n",
      " 9   SMA200          3141 non-null   float64\n",
      " 10  EMA12           3340 non-null   float64\n",
      " 11  EMA26           3340 non-null   float64\n",
      " 12  MACD            3340 non-null   float64\n",
      " 13  MACD_Signal     3340 non-null   float64\n",
      " 14  MACD_Histogram  3340 non-null   float64\n",
      " 15  avg_sentiment   3340 non-null   float64\n",
      "dtypes: float64(15), int64(1)\n",
      "memory usage: 443.6 KB\n",
      "None\n",
      "                               Close  High_GOOG   Low_GOOG  Open_GOOG  \\\n",
      "Datetime                                                                \n",
      "2023-03-03 14:30:00+00:00  93.650002  93.875000  92.660004  92.739998   \n",
      "2023-03-03 15:30:00+00:00  93.519997  93.900002  93.370003  93.650002   \n",
      "2023-03-03 16:30:00+00:00  93.669998  93.790001  93.370003  93.510002   \n",
      "2023-03-03 17:30:00+00:00  93.629997  93.785004  93.459999  93.660004   \n",
      "2023-03-03 18:30:00+00:00  93.900002  93.959999  93.550003  93.629997   \n",
      "\n",
      "                           Volume_GOOG  SMA20  SMA44  SMA50  SMA100  SMA200  \\\n",
      "Datetime                                                                      \n",
      "2023-03-03 14:30:00+00:00      6560170    NaN    NaN    NaN     NaN     NaN   \n",
      "2023-03-03 15:30:00+00:00      3932657    NaN    NaN    NaN     NaN     NaN   \n",
      "2023-03-03 16:30:00+00:00      2563078    NaN    NaN    NaN     NaN     NaN   \n",
      "2023-03-03 17:30:00+00:00      2797435    NaN    NaN    NaN     NaN     NaN   \n",
      "2023-03-03 18:30:00+00:00      2561836    NaN    NaN    NaN     NaN     NaN   \n",
      "\n",
      "                               EMA12      EMA26      MACD  MACD_Signal  \\\n",
      "Datetime                                                                 \n",
      "2023-03-03 14:30:00+00:00  93.650002  93.650002  0.000000     0.000000   \n",
      "2023-03-03 15:30:00+00:00  93.630001  93.640372 -0.010371    -0.002074   \n",
      "2023-03-03 16:30:00+00:00  93.636154  93.642566 -0.006412    -0.002942   \n",
      "2023-03-03 17:30:00+00:00  93.635207  93.641635 -0.006428    -0.003639   \n",
      "2023-03-03 18:30:00+00:00  93.675945  93.660773  0.015171     0.000123   \n",
      "\n",
      "                           MACD_Histogram  avg_sentiment  \n",
      "Datetime                                                  \n",
      "2023-03-03 14:30:00+00:00        0.000000            0.0  \n",
      "2023-03-03 15:30:00+00:00       -0.008297            0.0  \n",
      "2023-03-03 16:30:00+00:00       -0.003470            0.0  \n",
      "2023-03-03 17:30:00+00:00       -0.002789            0.0  \n",
      "2023-03-03 18:30:00+00:00        0.015048            0.0  \n",
      "                                Close   High_GOOG    Low_GOOG   Open_GOOG  \\\n",
      "Datetime                                                                    \n",
      "2025-02-07 16:30:00+00:00  185.445007  187.490005  185.110001  187.347504   \n",
      "2025-02-07 17:30:00+00:00  187.828506  187.839996  185.220001  185.440002   \n",
      "2025-02-07 18:30:00+00:00  187.369995  188.179993  186.869995  187.809998   \n",
      "2025-02-07 19:30:00+00:00  187.123703  187.789993  187.100006  187.369995   \n",
      "2025-02-07 20:30:00+00:00  187.190002  187.460007  186.899994  187.119995   \n",
      "\n",
      "                           Volume_GOOG       SMA20       SMA44       SMA50  \\\n",
      "Datetime                                                                     \n",
      "2025-02-07 16:30:00+00:00      3875821  193.806129  199.645465  199.439779   \n",
      "2025-02-07 17:30:00+00:00      2476479  192.851805  199.339294  199.258149   \n",
      "2025-02-07 18:30:00+00:00      2290224  191.866305  199.027931  199.069649   \n",
      "2025-02-07 19:30:00+00:00      2085096  190.834490  198.702105  198.872923   \n",
      "2025-02-07 20:30:00+00:00      2508441  190.680490  198.365060  198.653923   \n",
      "\n",
      "                               SMA100      SMA200       EMA12       EMA26  \\\n",
      "Datetime                                                                    \n",
      "2025-02-07 16:30:00+00:00  199.133849  196.719006  191.183341  194.642940   \n",
      "2025-02-07 17:30:00+00:00  199.035134  196.674799  190.667213  194.138167   \n",
      "2025-02-07 18:30:00+00:00  198.932634  196.623049  190.159948  193.636821   \n",
      "2025-02-07 19:30:00+00:00  198.820972  196.571467  189.692834  193.154368   \n",
      "2025-02-07 20:30:00+00:00  198.717272  196.520888  189.307783  192.712563   \n",
      "\n",
      "                               MACD  MACD_Signal  MACD_Histogram  \\\n",
      "Datetime                                                           \n",
      "2025-02-07 16:30:00+00:00 -3.459599    -2.862576       -0.597023   \n",
      "2025-02-07 17:30:00+00:00 -3.470954    -2.984251       -0.486703   \n",
      "2025-02-07 18:30:00+00:00 -3.476872    -3.082776       -0.394097   \n",
      "2025-02-07 19:30:00+00:00 -3.461534    -3.158527       -0.303007   \n",
      "2025-02-07 20:30:00+00:00 -3.404780    -3.207778       -0.197002   \n",
      "\n",
      "                           avg_sentiment  \n",
      "Datetime                                  \n",
      "2025-02-07 16:30:00+00:00        -0.2411  \n",
      "2025-02-07 17:30:00+00:00        -0.2411  \n",
      "2025-02-07 18:30:00+00:00        -0.2411  \n",
      "2025-02-07 19:30:00+00:00        -0.2411  \n",
      "2025-02-07 20:30:00+00:00        -0.2411  \n",
      "Data shape: (3340, 16)\n",
      "\n",
      "Saved GOOG data with sentiment to stock_data\\GOOG_data_with_sentiment.csv\n",
      "[DEBUG] MSFT stock data shape: (3340, 17), columns: ['Close', 'High_MSFT', 'Low_MSFT', 'Open_MSFT', 'Volume_MSFT', 'SMA20', 'SMA44', 'SMA50', 'SMA100', 'SMA200', 'EMA12', 'EMA26', 'MACD', 'MACD_Signal', 'MACD_Histogram', 'Datetime', 'Date']\n",
      "Fetching up to 200 Reddit posts for MSFT in r/wallstreetbets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebert\\AppData\\Local\\Temp\\ipykernel_23380\\1712123349.py:218: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df['avg_sentiment'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 200 posts for MSFT.\n",
      "[DEBUG] sentiment_daily shape: (169, 1), columns: ['avg_sentiment']\n",
      "\n",
      "--- Final merged DataFrame for MSFT ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3340 entries, 2023-03-03 14:30:00+00:00 to 2025-02-07 20:30:00+00:00\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Close           3340 non-null   float64\n",
      " 1   High_MSFT       3340 non-null   float64\n",
      " 2   Low_MSFT        3340 non-null   float64\n",
      " 3   Open_MSFT       3340 non-null   float64\n",
      " 4   Volume_MSFT     3340 non-null   int64  \n",
      " 5   SMA20           3321 non-null   float64\n",
      " 6   SMA44           3297 non-null   float64\n",
      " 7   SMA50           3291 non-null   float64\n",
      " 8   SMA100          3241 non-null   float64\n",
      " 9   SMA200          3141 non-null   float64\n",
      " 10  EMA12           3340 non-null   float64\n",
      " 11  EMA26           3340 non-null   float64\n",
      " 12  MACD            3340 non-null   float64\n",
      " 13  MACD_Signal     3340 non-null   float64\n",
      " 14  MACD_Histogram  3340 non-null   float64\n",
      " 15  avg_sentiment   3340 non-null   float64\n",
      "dtypes: float64(15), int64(1)\n",
      "memory usage: 443.6 KB\n",
      "None\n",
      "                                Close   High_MSFT    Low_MSFT   Open_MSFT  \\\n",
      "Datetime                                                                    \n",
      "2023-03-03 14:30:00+00:00  255.100006  255.250000  251.389999  251.880005   \n",
      "2023-03-03 15:30:00+00:00  253.744995  255.130005  253.330002  255.100006   \n",
      "2023-03-03 16:30:00+00:00  253.940002  254.029999  253.250000  253.759995   \n",
      "2023-03-03 17:30:00+00:00  255.050003  255.419998  253.690002  253.940002   \n",
      "2023-03-03 18:30:00+00:00  255.399902  255.449997  254.644302  255.050003   \n",
      "\n",
      "                           Volume_MSFT  SMA20  SMA44  SMA50  SMA100  SMA200  \\\n",
      "Datetime                                                                      \n",
      "2023-03-03 14:30:00+00:00      5476810    NaN    NaN    NaN     NaN     NaN   \n",
      "2023-03-03 15:30:00+00:00      2540013    NaN    NaN    NaN     NaN     NaN   \n",
      "2023-03-03 16:30:00+00:00      2202392    NaN    NaN    NaN     NaN     NaN   \n",
      "2023-03-03 17:30:00+00:00      1858632    NaN    NaN    NaN     NaN     NaN   \n",
      "2023-03-03 18:30:00+00:00      1526905    NaN    NaN    NaN     NaN     NaN   \n",
      "\n",
      "                                EMA12       EMA26      MACD  MACD_Signal  \\\n",
      "Datetime                                                                   \n",
      "2023-03-03 14:30:00+00:00  255.100006  255.100006  0.000000     0.000000   \n",
      "2023-03-03 15:30:00+00:00  254.891543  254.999635 -0.108092    -0.021618   \n",
      "2023-03-03 16:30:00+00:00  254.745152  254.921144 -0.175992    -0.052493   \n",
      "2023-03-03 17:30:00+00:00  254.792052  254.930689 -0.138637    -0.069722   \n",
      "2023-03-03 18:30:00+00:00  254.885568  254.965445 -0.079878    -0.071753   \n",
      "\n",
      "                           MACD_Histogram  avg_sentiment  \n",
      "Datetime                                                  \n",
      "2023-03-03 14:30:00+00:00        0.000000            0.0  \n",
      "2023-03-03 15:30:00+00:00       -0.086474            0.0  \n",
      "2023-03-03 16:30:00+00:00       -0.123499            0.0  \n",
      "2023-03-03 17:30:00+00:00       -0.068915            0.0  \n",
      "2023-03-03 18:30:00+00:00       -0.008125            0.0  \n",
      "                                Close   High_MSFT    Low_MSFT   Open_MSFT  \\\n",
      "Datetime                                                                    \n",
      "2025-02-07 16:30:00+00:00  410.180115  411.660004  409.559998  411.359985   \n",
      "2025-02-07 17:30:00+00:00  410.709991  411.339996  410.179993  410.179993   \n",
      "2025-02-07 18:30:00+00:00  408.285004  411.141998  408.279999  410.694397   \n",
      "2025-02-07 19:30:00+00:00  408.875000  409.159912  408.100006  408.269989   \n",
      "2025-02-07 20:30:00+00:00  409.760010  410.350006  408.809998  408.859985   \n",
      "\n",
      "                           Volume_MSFT       SMA20       SMA44       SMA50  \\\n",
      "Datetime                                                                     \n",
      "2025-02-07 16:30:00+00:00      2450726  413.646146  414.058350  416.984360   \n",
      "2025-02-07 17:30:00+00:00      1559172  413.556755  413.955168  416.326756   \n",
      "2025-02-07 18:30:00+00:00      1948018  413.373006  413.813816  415.632456   \n",
      "2025-02-07 19:30:00+00:00      1847588  413.201256  413.658248  414.968656   \n",
      "2025-02-07 20:30:00+00:00      2749459  413.113756  413.534385  414.264346   \n",
      "\n",
      "                               SMA100      SMA200       EMA12       EMA26  \\\n",
      "Datetime                                                                    \n",
      "2025-02-07 16:30:00+00:00  427.764086  426.064061  413.531966  414.595230   \n",
      "2025-02-07 17:30:00+00:00  427.572236  425.924961  413.097816  414.307435   \n",
      "2025-02-07 18:30:00+00:00  427.348586  425.775432  412.357384  413.861329   \n",
      "2025-02-07 19:30:00+00:00  427.117498  425.625857  411.821632  413.491971   \n",
      "2025-02-07 20:30:00+00:00  426.914074  425.479688  411.504460  413.215529   \n",
      "\n",
      "                               MACD  MACD_Signal  MACD_Histogram  \\\n",
      "Datetime                                                           \n",
      "2025-02-07 16:30:00+00:00 -1.063264    -1.028782       -0.034482   \n",
      "2025-02-07 17:30:00+00:00 -1.209618    -1.064949       -0.144669   \n",
      "2025-02-07 18:30:00+00:00 -1.503945    -1.152749       -0.351196   \n",
      "2025-02-07 19:30:00+00:00 -1.670339    -1.256267       -0.414072   \n",
      "2025-02-07 20:30:00+00:00 -1.711070    -1.347227       -0.363843   \n",
      "\n",
      "                           avg_sentiment  \n",
      "Datetime                                  \n",
      "2025-02-07 16:30:00+00:00            0.0  \n",
      "2025-02-07 17:30:00+00:00            0.0  \n",
      "2025-02-07 18:30:00+00:00            0.0  \n",
      "2025-02-07 19:30:00+00:00            0.0  \n",
      "2025-02-07 20:30:00+00:00            0.0  \n",
      "Data shape: (3340, 16)\n",
      "\n",
      "Saved MSFT data with sentiment to stock_data\\MSFT_data_with_sentiment.csv\n",
      "[DEBUG] AMZN stock data shape: (3340, 17), columns: ['Close', 'High_AMZN', 'Low_AMZN', 'Open_AMZN', 'Volume_AMZN', 'SMA20', 'SMA44', 'SMA50', 'SMA100', 'SMA200', 'EMA12', 'EMA26', 'MACD', 'MACD_Signal', 'MACD_Histogram', 'Datetime', 'Date']\n",
      "Fetching up to 200 Reddit posts for AMZN in r/wallstreetbets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebert\\AppData\\Local\\Temp\\ipykernel_23380\\1712123349.py:218: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df['avg_sentiment'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 200 posts for AMZN.\n",
      "[DEBUG] sentiment_daily shape: (175, 1), columns: ['avg_sentiment']\n",
      "\n",
      "--- Final merged DataFrame for AMZN ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3340 entries, 2023-03-03 14:30:00+00:00 to 2025-02-07 20:30:00+00:00\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Close           3340 non-null   float64\n",
      " 1   High_AMZN       3340 non-null   float64\n",
      " 2   Low_AMZN        3340 non-null   float64\n",
      " 3   Open_AMZN       3340 non-null   float64\n",
      " 4   Volume_AMZN     3340 non-null   int64  \n",
      " 5   SMA20           3321 non-null   float64\n",
      " 6   SMA44           3297 non-null   float64\n",
      " 7   SMA50           3291 non-null   float64\n",
      " 8   SMA100          3241 non-null   float64\n",
      " 9   SMA200          3141 non-null   float64\n",
      " 10  EMA12           3340 non-null   float64\n",
      " 11  EMA26           3340 non-null   float64\n",
      " 12  MACD            3340 non-null   float64\n",
      " 13  MACD_Signal     3340 non-null   float64\n",
      " 14  MACD_Histogram  3340 non-null   float64\n",
      " 15  avg_sentiment   3340 non-null   float64\n",
      "dtypes: float64(15), int64(1)\n",
      "memory usage: 443.6 KB\n",
      "None\n",
      "                               Close  High_AMZN   Low_AMZN  Open_AMZN  \\\n",
      "Datetime                                                                \n",
      "2023-03-03 14:30:00+00:00  94.714996  94.730003  92.660004  92.739998   \n",
      "2023-03-03 15:30:00+00:00  94.089996  94.750000  93.760002  94.714996   \n",
      "2023-03-03 16:30:00+00:00  94.110001  94.279999  93.910004  94.089996   \n",
      "2023-03-03 17:30:00+00:00  94.213600  94.400002  94.040001  94.110001   \n",
      "2023-03-03 18:30:00+00:00  94.683998  94.699997  94.050003  94.214996   \n",
      "\n",
      "                           Volume_AMZN  SMA20  SMA44  SMA50  SMA100  SMA200  \\\n",
      "Datetime                                                                      \n",
      "2023-03-03 14:30:00+00:00     16066850    NaN    NaN    NaN     NaN     NaN   \n",
      "2023-03-03 15:30:00+00:00      6859828    NaN    NaN    NaN     NaN     NaN   \n",
      "2023-03-03 16:30:00+00:00      5303826    NaN    NaN    NaN     NaN     NaN   \n",
      "2023-03-03 17:30:00+00:00      3947668    NaN    NaN    NaN     NaN     NaN   \n",
      "2023-03-03 18:30:00+00:00      4071756    NaN    NaN    NaN     NaN     NaN   \n",
      "\n",
      "                               EMA12      EMA26      MACD  MACD_Signal  \\\n",
      "Datetime                                                                 \n",
      "2023-03-03 14:30:00+00:00  94.714996  94.714996  0.000000     0.000000   \n",
      "2023-03-03 15:30:00+00:00  94.618842  94.668700 -0.049858    -0.009972   \n",
      "2023-03-03 16:30:00+00:00  94.540559  94.627315 -0.086756    -0.025328   \n",
      "2023-03-03 17:30:00+00:00  94.490258  94.596669 -0.106412    -0.041545   \n",
      "2023-03-03 18:30:00+00:00  94.520064  94.603138 -0.083074    -0.049851   \n",
      "\n",
      "                           MACD_Histogram  avg_sentiment  \n",
      "Datetime                                                  \n",
      "2023-03-03 14:30:00+00:00        0.000000            0.0  \n",
      "2023-03-03 15:30:00+00:00       -0.039886            0.0  \n",
      "2023-03-03 16:30:00+00:00       -0.061427            0.0  \n",
      "2023-03-03 17:30:00+00:00       -0.064867            0.0  \n",
      "2023-03-03 18:30:00+00:00       -0.033223            0.0  \n",
      "                                Close   High_AMZN    Low_AMZN   Open_AMZN  \\\n",
      "Datetime                                                                    \n",
      "2025-02-07 16:30:00+00:00  229.029999  229.889999  228.070007  229.130005   \n",
      "2025-02-07 17:30:00+00:00  230.330002  230.970001  228.929993  229.009995   \n",
      "2025-02-07 18:30:00+00:00  228.934998  230.990005  228.869995  230.320007   \n",
      "2025-02-07 19:30:00+00:00  228.899994  229.375000  228.630005  228.949997   \n",
      "2025-02-07 20:30:00+00:00  229.270004  230.039993  228.710007  228.884995   \n",
      "\n",
      "                           Volume_AMZN       SMA20       SMA44       SMA50  \\\n",
      "Datetime                                                                     \n",
      "2025-02-07 16:30:00+00:00      6746854  236.744360  237.321269  237.306529   \n",
      "2025-02-07 17:30:00+00:00      5357940  236.153111  237.238541  237.143617   \n",
      "2025-02-07 18:30:00+00:00      4588232  235.511111  237.115246  236.969817   \n",
      "2025-02-07 19:30:00+00:00      4026561  234.851611  236.982973  236.813616   \n",
      "2025-02-07 20:30:00+00:00      8612009  234.449586  236.852746  236.639417   \n",
      "\n",
      "                               SMA100      SMA200       EMA12       EMA26  \\\n",
      "Datetime                                                                    \n",
      "2025-02-07 16:30:00+00:00  235.315634  228.720552  234.504342  236.191753   \n",
      "2025-02-07 17:30:00+00:00  235.365234  228.730127  233.862136  235.757549   \n",
      "2025-02-07 18:30:00+00:00  235.406584  228.735322  233.104114  235.252175   \n",
      "2025-02-07 19:30:00+00:00  235.439077  228.744447  232.457327  234.781643   \n",
      "2025-02-07 20:30:00+00:00  235.475027  228.753197  231.966969  234.373374   \n",
      "\n",
      "                               MACD  MACD_Signal  MACD_Histogram  \\\n",
      "Datetime                                                           \n",
      "2025-02-07 16:30:00+00:00 -1.687411    -0.671447       -1.015965   \n",
      "2025-02-07 17:30:00+00:00 -1.895414    -0.916240       -0.979174   \n",
      "2025-02-07 18:30:00+00:00 -2.148061    -1.162604       -0.985456   \n",
      "2025-02-07 19:30:00+00:00 -2.324317    -1.394947       -0.929370   \n",
      "2025-02-07 20:30:00+00:00 -2.406404    -1.597238       -0.809166   \n",
      "\n",
      "                           avg_sentiment  \n",
      "Datetime                                  \n",
      "2025-02-07 16:30:00+00:00         0.1406  \n",
      "2025-02-07 17:30:00+00:00         0.1406  \n",
      "2025-02-07 18:30:00+00:00         0.1406  \n",
      "2025-02-07 19:30:00+00:00         0.1406  \n",
      "2025-02-07 20:30:00+00:00         0.1406  \n",
      "Data shape: (3340, 16)\n",
      "\n",
      "Saved AMZN data with sentiment to stock_data\\AMZN_data_with_sentiment.csv\n",
      "[DEBUG] NVDA stock data shape: (3340, 17), columns: ['Close', 'High_NVDA', 'Low_NVDA', 'Open_NVDA', 'Volume_NVDA', 'SMA20', 'SMA44', 'SMA50', 'SMA100', 'SMA200', 'EMA12', 'EMA26', 'MACD', 'MACD_Signal', 'MACD_Histogram', 'Datetime', 'Date']\n",
      "Fetching up to 200 Reddit posts for NVDA in r/wallstreetbets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebert\\AppData\\Local\\Temp\\ipykernel_23380\\1712123349.py:218: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df['avg_sentiment'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 200 posts for NVDA.\n",
      "[DEBUG] sentiment_daily shape: (145, 1), columns: ['avg_sentiment']\n",
      "\n",
      "--- Final merged DataFrame for NVDA ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3340 entries, 2023-03-03 14:30:00+00:00 to 2025-02-07 20:30:00+00:00\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Close           3340 non-null   float64\n",
      " 1   High_NVDA       3340 non-null   float64\n",
      " 2   Low_NVDA        3340 non-null   float64\n",
      " 3   Open_NVDA       3340 non-null   float64\n",
      " 4   Volume_NVDA     3340 non-null   int64  \n",
      " 5   SMA20           3321 non-null   float64\n",
      " 6   SMA44           3297 non-null   float64\n",
      " 7   SMA50           3291 non-null   float64\n",
      " 8   SMA100          3241 non-null   float64\n",
      " 9   SMA200          3141 non-null   float64\n",
      " 10  EMA12           3340 non-null   float64\n",
      " 11  EMA26           3340 non-null   float64\n",
      " 12  MACD            3340 non-null   float64\n",
      " 13  MACD_Signal     3340 non-null   float64\n",
      " 14  MACD_Histogram  3340 non-null   float64\n",
      " 15  avg_sentiment   3340 non-null   float64\n",
      "dtypes: float64(15), int64(1)\n",
      "memory usage: 443.6 KB\n",
      "None\n",
      "                                Close   High_NVDA    Low_NVDA   Open_NVDA  \\\n",
      "Datetime                                                                    \n",
      "2023-03-03 14:30:00+00:00  233.410095  234.929993  231.300003  233.199997   \n",
      "2023-03-03 15:30:00+00:00  232.339996  234.100006  231.860001  233.440002   \n",
      "2023-03-03 16:30:00+00:00  233.750000  233.759995  231.386398  232.346497   \n",
      "2023-03-03 17:30:00+00:00  235.669907  236.070007  233.419800  233.770004   \n",
      "2023-03-03 18:30:00+00:00  236.970596  237.039993  235.399994  235.699997   \n",
      "\n",
      "                           Volume_NVDA  SMA20  SMA44  SMA50  SMA100  SMA200  \\\n",
      "Datetime                                                                      \n",
      "2023-03-03 14:30:00+00:00     10094629    NaN    NaN    NaN     NaN     NaN   \n",
      "2023-03-03 15:30:00+00:00      4601483    NaN    NaN    NaN     NaN     NaN   \n",
      "2023-03-03 16:30:00+00:00      3815060    NaN    NaN    NaN     NaN     NaN   \n",
      "2023-03-03 17:30:00+00:00      4450644    NaN    NaN    NaN     NaN     NaN   \n",
      "2023-03-03 18:30:00+00:00      3677958    NaN    NaN    NaN     NaN     NaN   \n",
      "\n",
      "                                EMA12       EMA26      MACD  MACD_Signal  \\\n",
      "Datetime                                                                   \n",
      "2023-03-03 14:30:00+00:00  233.410095  233.410095  0.000000     0.000000   \n",
      "2023-03-03 15:30:00+00:00  233.245465  233.330829 -0.085364    -0.017073   \n",
      "2023-03-03 16:30:00+00:00  233.323085  233.361878 -0.038793    -0.021417   \n",
      "2023-03-03 17:30:00+00:00  233.684135  233.532843  0.151291     0.013125   \n",
      "2023-03-03 18:30:00+00:00  234.189744  233.787492  0.402253     0.090950   \n",
      "\n",
      "                           MACD_Histogram  avg_sentiment  \n",
      "Datetime                                                  \n",
      "2023-03-03 14:30:00+00:00        0.000000            0.0  \n",
      "2023-03-03 15:30:00+00:00       -0.068291            0.0  \n",
      "2023-03-03 16:30:00+00:00       -0.017376            0.0  \n",
      "2023-03-03 17:30:00+00:00        0.138167            0.0  \n",
      "2023-03-03 18:30:00+00:00        0.311302            0.0  \n",
      "                                Close   High_NVDA    Low_NVDA   Open_NVDA  \\\n",
      "Datetime                                                                    \n",
      "2025-02-07 16:30:00+00:00  128.235001  129.059601  127.599998  128.699997   \n",
      "2025-02-07 17:30:00+00:00  129.255005  129.649994  128.020004  128.229996   \n",
      "2025-02-07 18:30:00+00:00  128.130005  129.429993  127.908798  129.259903   \n",
      "2025-02-07 19:30:00+00:00  128.948502  129.089905  127.970001  128.139999   \n",
      "2025-02-07 20:30:00+00:00  129.860001  130.000000  128.820007  128.945007   \n",
      "\n",
      "                           Volume_NVDA       SMA20       SMA44       SMA50  \\\n",
      "Datetime                                                                     \n",
      "2025-02-07 16:30:00+00:00     27757064  125.073130  122.443634  122.390966   \n",
      "2025-02-07 17:30:00+00:00     17653887  125.570380  122.675459  122.516098   \n",
      "2025-02-07 18:30:00+00:00     16675456  126.053630  122.876369  122.646898   \n",
      "2025-02-07 19:30:00+00:00     16455557  126.567056  123.091675  122.807668   \n",
      "2025-02-07 20:30:00+00:00     21996032  126.944556  123.282698  122.941868   \n",
      "\n",
      "                               SMA100      SMA200       EMA12       EMA26  \\\n",
      "Datetime                                                                    \n",
      "2025-02-07 16:30:00+00:00  129.461859  133.808738  127.118579  125.113286   \n",
      "2025-02-07 17:30:00+00:00  129.373117  133.751191  127.447260  125.420080   \n",
      "2025-02-07 18:30:00+00:00  129.274732  133.698241  127.552297  125.620815   \n",
      "2025-02-07 19:30:00+00:00  129.181617  133.646133  127.767098  125.867310   \n",
      "2025-02-07 20:30:00+00:00  129.099317  133.595733  128.089083  126.163065   \n",
      "\n",
      "                               MACD  MACD_Signal  MACD_Histogram  \\\n",
      "Datetime                                                           \n",
      "2025-02-07 16:30:00+00:00  2.005293     1.634151        0.371142   \n",
      "2025-02-07 17:30:00+00:00  2.027180     1.712757        0.314423   \n",
      "2025-02-07 18:30:00+00:00  1.931483     1.756502        0.174980   \n",
      "2025-02-07 19:30:00+00:00  1.899788     1.785159        0.114629   \n",
      "2025-02-07 20:30:00+00:00  1.926018     1.813331        0.112687   \n",
      "\n",
      "                           avg_sentiment  \n",
      "Datetime                                  \n",
      "2025-02-07 16:30:00+00:00            0.0  \n",
      "2025-02-07 17:30:00+00:00            0.0  \n",
      "2025-02-07 18:30:00+00:00            0.0  \n",
      "2025-02-07 19:30:00+00:00            0.0  \n",
      "2025-02-07 20:30:00+00:00            0.0  \n",
      "Data shape: (3340, 16)\n",
      "\n",
      "Saved NVDA data with sentiment to stock_data\\NVDA_data_with_sentiment.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebert\\AppData\\Local\\Temp\\ipykernel_23380\\1712123349.py:218: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df['avg_sentiment'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import praw\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Ensure the VADER lexicon is downloaded\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# --- Reddit API Credentials ---\n",
    "REDDIT_CLIENT_ID = \"VQ-NOvyPWyJvGZs1ifD0Ww\"\n",
    "REDDIT_CLIENT_SECRET = \"BX_Dlp6miv2eMo4qt5JY_imgYVyMBA\"\n",
    "REDDIT_USER_AGENT = \"StockSentimentAnalysis/0.1 by Joseph\"\n",
    "\n",
    "# Initialize the Reddit client (PRAW)\n",
    "reddit = praw.Reddit(\n",
    "    client_id=REDDIT_CLIENT_ID,\n",
    "    client_secret=REDDIT_CLIENT_SECRET,\n",
    "    user_agent=REDDIT_USER_AGENT\n",
    ")\n",
    "\n",
    "def fetch_intraday_chunks(ticker, start_date, end_date, interval=\"1h\", max_days=60):\n",
    "    \"\"\"\n",
    "    Fetch intraday data in chunks for a given ticker from start_date to end_date,\n",
    "    avoiding yfinance's ~60-day intraday limit by splitting the date range.\n",
    "    \n",
    "    Returns a single DataFrame for the entire period, with a single-level DatetimeIndex.\n",
    "    \"\"\"\n",
    "    start_dt = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end_dt = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    \n",
    "    all_data = []\n",
    "    current_start = start_dt\n",
    "\n",
    "    while current_start < end_dt:\n",
    "        current_end = current_start + timedelta(days=max_days)\n",
    "        if current_end > end_dt:\n",
    "            current_end = end_dt\n",
    "\n",
    "        chunk_start_str = current_start.strftime(\"%Y-%m-%d\")\n",
    "        chunk_end_str = current_end.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        print(f\"Fetching {ticker} data from {chunk_start_str} to {chunk_end_str} with {interval} interval...\")\n",
    "        chunk_data = yf.download(ticker, start=chunk_start_str, end=chunk_end_str, interval=interval)\n",
    "        \n",
    "        if not chunk_data.empty:\n",
    "            all_data.append(chunk_data)\n",
    "        else:\n",
    "            print(f\"No data returned for {ticker} from {chunk_start_str} to {chunk_end_str}.\")\n",
    "        \n",
    "        current_start = current_end + timedelta(days=1)\n",
    "    \n",
    "    if all_data:\n",
    "        full_data = pd.concat(all_data)\n",
    "        full_data.sort_index(inplace=True)\n",
    "        \n",
    "        # Ensure index is a proper DatetimeIndex\n",
    "        if not pd.api.types.is_datetime64_any_dtype(full_data.index):\n",
    "            print(\"[DEBUG] Converting index to datetime...\")\n",
    "            full_data.index = pd.to_datetime(full_data.index, errors='coerce')\n",
    "        \n",
    "        # Flatten multi-level columns if needed\n",
    "        if isinstance(full_data.columns, pd.MultiIndex):\n",
    "            full_data.columns = [\n",
    "                \"_\".join(col) if isinstance(col, tuple) else col\n",
    "                for col in full_data.columns\n",
    "            ]\n",
    "        \n",
    "        # Drop top level if we have a multi-level index (e.g., (ticker, datetime))\n",
    "        if full_data.index.nlevels > 1:\n",
    "            print(\"[DEBUG] Dropping the top index level...\")\n",
    "            full_data.index = full_data.index.droplevel(0)\n",
    "        \n",
    "        return full_data\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "def add_indicators(data, sma_windows=[20, 44, 50, 100, 200]):\n",
    "    \"\"\"\n",
    "    Calculate technical indicators and add them as new columns to the DataFrame.\n",
    "    \n",
    "    Calculates:\n",
    "      - SMA (Simple Moving Average) for each window in sma_windows.\n",
    "      - MACD components (MACD line, Signal line, and Histogram).\n",
    "      \n",
    "    Parameters:\n",
    "        data (DataFrame): DataFrame containing stock data.\n",
    "        sma_windows (list): List of window periods for SMA calculation.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: DataFrame with additional indicator columns.\n",
    "    \"\"\"\n",
    "    data.rename(columns=lambda x: \"Close\" if \"Close\" in x else x, inplace=True)\n",
    "    if not data.empty and \"Close\" in data.columns:\n",
    "        # Calculate SMAs for each specified window\n",
    "        for window in sma_windows:\n",
    "            data[f'SMA{window}'] = data['Close'].rolling(window=window).mean()\n",
    "        \n",
    "        # Calculate MACD components:\n",
    "        # 12-period EMA and 26-period EMA\n",
    "        data['EMA12'] = data['Close'].ewm(span=12, adjust=False).mean()\n",
    "        data['EMA26'] = data['Close'].ewm(span=26, adjust=False).mean()\n",
    "        # MACD Line\n",
    "        data['MACD'] = data['EMA12'] - data['EMA26']\n",
    "        # Signal Line: 9-period EMA of MACD\n",
    "        data['MACD_Signal'] = data['MACD'].ewm(span=9, adjust=False).mean()\n",
    "        # Histogram: MACD - Signal Line\n",
    "        data['MACD_Histogram'] = data['MACD'] - data['MACD_Signal']\n",
    "        \n",
    "        # Debug: print the columns to verify technical indicators are added\n",
    "        print(\"[DEBUG] Technical indicator columns added:\", data.columns.tolist())\n",
    "    return data\n",
    "\n",
    "def get_stocks_data(ticker_list, start_date, end_date, interval=\"1h\", max_days=60):\n",
    "    \"\"\"\n",
    "    Fetch historical intraday stock data for each ticker over a large date range by chunking.\n",
    "    Returns a dictionary {ticker: DataFrame}.\n",
    "    \"\"\"\n",
    "    stocks_data = {}\n",
    "    for ticker in ticker_list:\n",
    "        data = fetch_intraday_chunks(ticker, start_date, end_date, interval, max_days)\n",
    "        # Add SMA and MACD technical indicators\n",
    "        data = add_indicators(data, sma_windows=[20, 44, 50, 100, 200])\n",
    "        # Add time features\n",
    "\n",
    "        stocks_data[ticker] = data\n",
    "    return stocks_data\n",
    "\n",
    "def fetch_reddit_posts(ticker, limit=200, subreddit=\"wallstreetbets\"):\n",
    "    \"\"\"\n",
    "    Fetch up to 'limit' Reddit posts from a subreddit that mention the ticker.\n",
    "    (PRAW doesn't allow date-based filtering, so we do a broad search and later\n",
    "    aggregate by date in Python.)\n",
    "    \n",
    "    Returns: list of dict, each with {'created': datetime, 'text': ...}\n",
    "    \"\"\"\n",
    "    print(f\"Fetching up to {limit} Reddit posts for {ticker} in r/{subreddit}...\")\n",
    "    posts = []\n",
    "    try:\n",
    "        for submission in reddit.subreddit(subreddit).search(ticker, limit=limit):\n",
    "            created_dt = pd.to_datetime(submission.created_utc, unit='s', utc=True)\n",
    "            created_dt = created_dt.tz_localize(None)\n",
    "            text = f\"{submission.title} {submission.selftext}\"\n",
    "            posts.append({'created': created_dt, 'text': text})\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching Reddit posts: {e}\")\n",
    "    print(f\"Fetched {len(posts)} posts for {ticker}.\")\n",
    "    return posts\n",
    "\n",
    "def analyze_sentiment(posts):\n",
    "    \"\"\"\n",
    "    Perform VADER sentiment analysis on each post.\n",
    "    Returns a DataFrame with columns ['created', 'compound'].\n",
    "    \"\"\"\n",
    "    if not posts:\n",
    "        return pd.DataFrame(columns=[\"created\", \"compound\"])\n",
    "    \n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    results = []\n",
    "    for p in posts:\n",
    "        scores = sid.polarity_scores(p['text'])\n",
    "        results.append({\n",
    "            'created': p['created'],\n",
    "            'compound': scores['compound']\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def aggregate_sentiment_by_date(sentiment_df):\n",
    "    \"\"\"\n",
    "    Convert each post's 'created' datetime to a date, then average the 'compound' score by date.\n",
    "    Returns a DataFrame indexed by 'Date' with column 'avg_sentiment'.\n",
    "    \"\"\"\n",
    "    if sentiment_df.empty:\n",
    "        return pd.DataFrame(columns=[\"avg_sentiment\"])\n",
    "    \n",
    "    sentiment_df['Date'] = sentiment_df['created'].dt.date\n",
    "    grouped = sentiment_df.groupby('Date')['compound'].mean().reset_index()\n",
    "    grouped.rename(columns={'compound': 'avg_sentiment'}, inplace=True)\n",
    "    grouped.set_index('Date', inplace=True)\n",
    "    return grouped\n",
    "\n",
    "def merge_stock_with_sentiment(stock_df, ticker):\n",
    "    \"\"\"\n",
    "    1) Store original intraday index in 'Datetime' column\n",
    "    2) Create a 'Date' column from that intraday index\n",
    "    3) Reset the index to a RangeIndex\n",
    "    4) Fetch & analyze Reddit posts for 'ticker'\n",
    "    5) Aggregate sentiment by date\n",
    "    6) Merge on 'Date'\n",
    "    7) Restore the original intraday index as row labels\n",
    "    8) Return a DataFrame with 'avg_sentiment'\n",
    "    \"\"\"\n",
    "    if stock_df.empty:\n",
    "        return stock_df\n",
    "    \n",
    "    # 1) Store original intraday index in a new column\n",
    "    stock_df['Datetime'] = stock_df.index\n",
    "    \n",
    "    # 2) Create a 'Date' column from that intraday index\n",
    "    stock_df['Date'] = stock_df.index.date\n",
    "    \n",
    "    # 3) Reset the index\n",
    "    stock_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    print(f\"[DEBUG] {ticker} stock data shape: {stock_df.shape}, columns: {stock_df.columns.tolist()}\")\n",
    "\n",
    "    # 4) Fetch & analyze Reddit posts\n",
    "    posts = fetch_reddit_posts(ticker, limit=200)\n",
    "    sentiment_df = analyze_sentiment(posts)\n",
    "    sentiment_daily = aggregate_sentiment_by_date(sentiment_df)\n",
    "    \n",
    "    print(f\"[DEBUG] sentiment_daily shape: {sentiment_daily.shape}, columns: {sentiment_daily.columns.tolist()}\")\n",
    "    \n",
    "    # 5) Merge on 'Date'\n",
    "    merged_df = stock_df.merge(sentiment_daily, how='left', left_on='Date', right_on='Date')\n",
    "    merged_df['avg_sentiment'].fillna(0, inplace=True)\n",
    "    \n",
    "    # 7) Restore the original intraday timestamps as row labels\n",
    "    #    We'll set the index to 'Datetime'\n",
    "    merged_df.set_index('Datetime', inplace=True)\n",
    "    merged_df.drop('Date', axis=1, inplace=True)\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "def save_stocks_to_csv(stocks_data, output_dir=\".\"):\n",
    "    \"\"\"\n",
    "    For each ticker:\n",
    "      1) Merge the chunked stock data with Reddit sentiment\n",
    "      2) Print the final merged DataFrame\n",
    "      3) Save to CSV\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    for ticker, data in stocks_data.items():\n",
    "        if data.empty:\n",
    "            print(f\"No data for {ticker}; skipping sentiment merge and CSV save.\")\n",
    "            continue\n",
    "        \n",
    "        merged_df = merge_stock_with_sentiment(data, ticker)\n",
    "        \n",
    "        print(f\"\\n--- Final merged DataFrame for {ticker} ---\")\n",
    "        print(merged_df.info())\n",
    "        print(merged_df.head(5))\n",
    "        print(merged_df.tail(5))\n",
    "        print(f\"Data shape: {merged_df.shape}\\n\")\n",
    "        \n",
    "        file_path = os.path.join(output_dir, f\"{ticker}_data_with_sentiment.csv\")\n",
    "        merged_df.to_csv(file_path)\n",
    "        print(f\"Saved {ticker} data with sentiment to {file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tickers = [\"AAPL\", \"GOOG\", \"MSFT\", \"AMZN\", \"NVDA\"]\n",
    "    start_date = \"2023-01-01\"\n",
    "    end_date = \"2025-02-10\"\n",
    "    \n",
    "    stocks_data = get_stocks_data(tickers, start_date, end_date, interval=\"1h\", max_days=60)\n",
    "    save_stocks_to_csv(stocks_data, output_dir=\"stock_data\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
